{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OpenSetSegmentation.ipynb","provenance":[],"collapsed_sections":["_Of24jjSXv8s","mzJJvRw_Xs7t"],"mount_file_id":"1J8CPbbCATMySHJWI-sa_A_Hb5QP_t5QC","authorship_tag":"ABX9TyO0FYSmf+mkn5E2BJuYd9nk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Fxk4Gu1ZUYQt"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from tqdm.notebook import tqdm\n","import cv2\n","import sys\n","from skimage import io\n","from skimage import color\n","from skimage import transform\n","from skimage import util\n","import time"]},{"cell_type":"code","source":["import torch\n","from torch.utils import data\n","import torch.nn as nn\n","from torch.nn import init\n","from torch.utils.data import DataLoader\n","import albumentations as album \n","from torch.autograd import Variable\n","import torchvision.models as models\n","import torchvision.transforms as T\n","from torchsummary import summary\n","import torch.nn.functional as F"],"metadata":{"id":"iD_AkmqPXWJO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["potsdam = \"/content/drive/MyDrive/BTPII/Potsdam\""],"metadata":{"id":"TadRerCahTuz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Custom Dataset"],"metadata":{"id":"eascsvurX7jV"}},{"cell_type":"code","source":["class ListDataset(data.Dataset):\n","\n","    def __init__(self, root, dataset, mode, crop_size, normalization='minmax', hidden_classes=None, overlap=False, use_dsm=False):\n","\n","        # Initializing variables.\n","        self.root = root\n","        self.dataset = dataset\n","        self.mode = mode\n","        self.crop_size = crop_size\n","        self.normalization = normalization\n","        self.hidden_classes = hidden_classes\n","        self.overlap = overlap\n","        self.use_dsm = use_dsm\n","        \n","        self.num_classes = 5 # For Vaihingen and Potsdam.\n","            \n","        if self.hidden_classes is not None:\n","            self.n_classes = self.num_classes - len(hidden_classes)\n","        else:\n","            self.n_classes = self.num_classes\n","\n","        # Creating list of paths.\n","        self.imgs = self.make_dataset()\n","\n","        # Check for consistency in list.\n","        if len(self.imgs) == 0:\n","\n","            raise (RuntimeError('Found 0 images, please check the data set'))\n","\n","    def make_dataset(self):\n","\n","        # Making sure the mode is correct.\n","        assert self.mode in ['Train', 'Test', 'Val']\n","\n","        # Setting string for the mode.\n","        img_dir = os.path.join(self.root, self.mode, 'Images')\n","        msk_dir = os.path.join(self.root, self.mode, 'Masks')\n","        if self.use_dsm:\n","            dsm_dir = os.path.join(self.root, self.mode, 'NDSM')\n","\n","        # if self.mode == 'Val':\n","        #     img_dir = os.path.join(self.root, 'Train', 'Images')\n","        #     msk_dir = os.path.join(self.root, 'Train', 'Masks')\n","        #     if self.use_dsm:\n","        #         dsm_dir = os.path.join(self.root, 'Train', 'NDSM')\n","\n","        data_list = sorted([f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))])\n","\n","        # Creating list containing image and ground truth paths.\n","        items = []\n","        if self.dataset == 'Vaihingen':\n","            for it in data_list:\n","                item = (\n","                    os.path.join(img_dir, it),\n","                    os.path.join(msk_dir, it),\n","                    # os.path.join(dsm_dir, it.replace('top_mosaic_09cm_area', 'dsm_09cm_matching_area').replace('.tif', '_normalized.jpg'))\n","                )\n","                items.append(item)\n","        elif self.dataset == 'Potsdam':\n","            for it in data_list:\n","                if self.use_dsm:\n","                    item = (\n","                        os.path.join(img_dir, it),\n","                        os.path.join(msk_dir, it.replace('_IRRG.tif', '_label.tif')),\n","                        # os.path.join(msk_dir, it.replace('_IRRG.tif', '_label_noBoundary.tif')),\n","                        os.path.join(dsm_dir, it.replace('top_potsdam_', 'dsm_potsdam_').replace('_IRRG.tif', '_normalized_lastools.jpg'))\n","                    )\n","                else:\n","                    item = (\n","                        os.path.join(img_dir, it),\n","                        os.path.join(msk_dir, it.replace('_IRRG.tif', '_label.tif')),\n","                        # os.path.join(msk_dir, it.replace('_IRRG.tif', '_label_noBoundary.tif')),\n","                        # os.path.join(dsm_dir, it.replace('top_potsdam_', 'dsm_potsdam_').replace('_IRRG.tif', '_normalized_lastools.jpg'))\n","                    )\n","                items.append(item)\n","        \n","        # Returning list.\n","        return items\n","    \n","    def random_crops(self, img, msk, msk_true, n_crops):\n","        \n","        img_crop_list = []\n","        msk_crop_list = []\n","        msk_true_crop_list = []\n","        \n","        rand_fliplr = np.random.random() > 0.50\n","        rand_flipud = np.random.random() > 0.50\n","        rand_rotate = np.random.random()\n","        \n","        for i in range(n_crops):\n","            \n","            rand_y = np.random.randint(msk.shape[0] - self.crop_size[0])\n","            rand_x = np.random.randint(msk.shape[1] - self.crop_size[1])\n","\n","            img_patch = img[rand_y:(rand_y + self.crop_size[0]),\n","                            rand_x:(rand_x + self.crop_size[1])]\n","            msk_patch = msk[rand_y:(rand_y + self.crop_size[0]),\n","                            rand_x:(rand_x + self.crop_size[1])]\n","            msk_true_patch = msk_true[rand_y:(rand_y + self.crop_size[0]),\n","                                      rand_x:(rand_x + self.crop_size[1])]\n","            \n","            if rand_fliplr:\n","                img_patch = np.fliplr(img_patch)\n","                msk_patch = np.fliplr(msk_patch)\n","                msk_true_patch = np.fliplr(msk_true_patch)\n","            if rand_flipud:\n","                img_patch = np.flipud(img_patch)\n","                msk_patch = np.flipud(msk_patch)\n","                msk_true_patch = np.flipud(msk_true_patch)\n","            \n","            if rand_rotate < 0.25:\n","                img_patch = transform.rotate(img_patch, 270, order=1, preserve_range=True)\n","                msk_patch = transform.rotate(msk_patch, 270, order=0, preserve_range=True)\n","                msk_true_patch = transform.rotate(msk_true_patch, 270, order=0, preserve_range=True)\n","            elif rand_rotate < 0.50:\n","                img_patch = transform.rotate(img_patch, 180, order=1, preserve_range=True)\n","                msk_patch = transform.rotate(msk_patch, 180, order=0, preserve_range=True)\n","                msk_true_patch = transform.rotate(msk_true_patch, 180, order=0, preserve_range=True)\n","            elif rand_rotate < 0.75:\n","                img_patch = transform.rotate(img_patch, 90, order=1, preserve_range=True)\n","                msk_patch = transform.rotate(msk_patch, 90, order=0, preserve_range=True)\n","                msk_true_patch = transform.rotate(msk_true_patch, 90, order=0, preserve_range=True)\n","                \n","            img_patch = img_patch.astype(np.float32)\n","            msk_patch = msk_patch.astype(np.int64)\n","            msk_true_patch = msk_true_patch.astype(np.int64)\n","            \n","            img_crop_list.append(img_patch)\n","            msk_crop_list.append(msk_patch)\n","            msk_true_crop_list.append(msk_true_patch)\n","        \n","        img = np.asarray(img_crop_list)\n","        msk = np.asarray(msk_crop_list)\n","        msk_true = np.asarray(msk_true_crop_list)\n","        \n","        return img, msk, msk_true\n","        \n","    def test_crops(self, img, msk, msk_true):\n","        \n","        n_channels = 3\n","        if self.use_dsm:\n","            n_channels = 4\n","        if self.overlap:\n","            w_img = util.view_as_windows(img,\n","                                         (self.crop_size[0], self.crop_size[1], n_channels),\n","                                         (self.crop_size[0] // 2, self.crop_size[1] // 2, n_channels)).squeeze()\n","            w_msk = util.view_as_windows(msk,\n","                                         (self.crop_size[0], self.crop_size[1]),\n","                                         (self.crop_size[0] // 2, self.crop_size[1] // 2))\n","            w_msk_true = util.view_as_windows(msk_true,\n","                                              (self.crop_size[0], self.crop_size[1]),\n","                                              (self.crop_size[0] // 2, self.crop_size[1] // 2))\n","        else:\n","            w_img = util.view_as_blocks(img, (self.crop_size[0], self.crop_size[1], n_channels)).squeeze()\n","            w_msk = util.view_as_blocks(msk, (self.crop_size[0], self.crop_size[1]))\n","            w_msk_true = util.view_as_blocks(msk_true, (self.crop_size[0], self.crop_size[1]))\n","        \n","        return w_img, w_msk, w_msk_true\n","        \n","    def shift_labels(self, msk):\n","        \n","        msk_true = np.copy(msk)\n","        \n","        cont = 0\n","        for h_c in self.hidden_classes:\n","            \n","            msk[msk == h_c - cont] = 100\n","            for c in range(h_c - cont + 1, self.num_classes):\n","                msk[msk == c] = c - 1\n","                # msk_true[msk_true == c] = c - 1\n","            cont = cont + 1\n","        \n","        # msk_true[msk == 100] = self.num_classes - len(self.hidden_classes)\n","        msk[msk == 100] = self.num_classes #- len(self.hidden_classes)\n","        \n","        return msk, msk_true\n","    \n","    def mask_to_class(self, msk):\n","    \n","        msk = msk.astype(np.int64)\n","        new = np.zeros((msk.shape[0], msk.shape[1]), dtype=np.int64)\n","        \n","        msk = msk // 255\n","        msk = msk * (1, 7, 49)\n","        msk = msk.sum(axis=2)\n","\n","        new[msk == 1 + 7 + 49] = 0 # Street.\n","        new[msk ==         49] = 1 # Building.\n","        new[msk ==     7 + 49] = 2 # Grass.\n","        new[msk ==     7     ] = 3 # Tree.\n","        new[msk == 1 + 7     ] = 4 # Car.\n","        new[msk == 1         ] = 5 # Surfaces.\n","        new[msk == 0         ] = 6 # Boundaries.\n","\n","        return new\n","        \n","    def __getitem__(self, index):\n","        \n","        # Reading items from list.\n","        if self.use_dsm:\n","            img_path, msk_path, dsm_path = self.imgs[index]\n","        else:\n","            img_path, msk_path = self.imgs[index]\n","        \n","        # Reading images.\n","        img_raw = io.imread(img_path)\n","        msk_raw = io.imread(msk_path)\n","        if self.use_dsm:\n","            dsm_raw = io.imread(dsm_path)\n","            \n","        if len(img_raw.shape) == 2:\n","            img_raw = color.gray2rgb(img_raw)\n","        \n","        if self.use_dsm:\n","            img = np.full((img_raw.shape[0] + self.crop_size[0] - (img_raw.shape[0] % self.crop_size[0]),\n","                           img_raw.shape[1] + self.crop_size[1] - (img_raw.shape[1] % self.crop_size[1]),\n","                           img_raw.shape[2] + 1),\n","                          fill_value=0.0,\n","                          dtype=np.float32)\n","        else:\n","            img = np.full((img_raw.shape[0] + self.crop_size[0] - (img_raw.shape[0] % self.crop_size[0]),\n","                           img_raw.shape[1] + self.crop_size[1] - (img_raw.shape[1] % self.crop_size[1]),\n","                           img_raw.shape[2]),\n","                          fill_value=0.0,\n","                          dtype=np.float32)\n","        \n","        msk = np.full((msk_raw.shape[0] + self.crop_size[0] - (msk_raw.shape[0] % self.crop_size[0]),\n","                       msk_raw.shape[1] + self.crop_size[1] - (msk_raw.shape[1] % self.crop_size[1]),\n","                       msk_raw.shape[2]),\n","                      fill_value=0,\n","                      dtype=np.int64)\n","        \n","        img[:img_raw.shape[0], :img_raw.shape[1], :img_raw.shape[2]] = img_raw\n","        if self.use_dsm:\n","            img[:dsm_raw.shape[0], :dsm_raw.shape[1], -1] = dsm_raw\n","        msk[:msk_raw.shape[0], :msk_raw.shape[1]] = msk_raw\n","        \n","        msk = self.mask_to_class(msk)\n","        \n","        msk, msk_true = self.shift_labels(msk)\n","        \n","        # Normalization.\n","        img = (img / 255) - 0.5\n","        \n","        if self.mode == 'Train':\n","            \n","            img, msk, msk_true = self.random_crops(img, msk, msk_true, 3)\n","            \n","            img = np.transpose(img, (0, 3, 1, 2))\n","        \n","        elif self.mode == 'Val':\n","            \n","            img, msk, msk_true = self.test_crops(img, msk, msk_true)\n","            \n","            img = np.transpose(img, (0, 1, 4, 2, 3))\n","            msk = np.transpose(msk, (0, 1, 2, 3))\n","            msk_true = np.transpose(msk_true, (0, 1, 2, 3))\n","        \n","        elif self.mode == 'Test':\n","            \n","            img, msk, msk_true = self.test_crops(img, msk, msk_true)\n","            \n","            img = np.transpose(img, (0, 1, 4, 2, 3))\n","            msk = np.transpose(msk, (0, 1, 2, 3))\n","            msk_true = np.transpose(msk_true, (0, 1, 2, 3))\n","        \n","        msk[msk == self.num_classes + 1] = self.num_classes\n","        msk_true[msk_true == self.num_classes + 1] = self.num_classes\n","\n","        # Splitting path.\n","        spl = img_path.split('/')\n","\n","        # Turning to tensors.\n","        img = torch.from_numpy(img)\n","        msk = torch.from_numpy(msk)\n","        msk_true = torch.from_numpy(msk_true)\n","\n","        # Returning to iterator.\n","        return img, msk, msk_true, spl[-1]\n","\n","    def __len__(self):\n","\n","        return len(self.imgs)"],"metadata":{"id":"1r0_P2grh17A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### FCN Models"],"metadata":{"id":"_Of24jjSXv8s"}},{"cell_type":"code","source":["class FCNWideResNet50(nn.Module):\n","    \n","    def __init__(self, input_channels, num_classes, pretrained=True, skip=True, hidden_classes=None):\n","\n","        super(FCNWideResNet50, self).__init__()\n","\n","        self.skip = skip\n","        \n","        # ResNet-50 with Skip Connections (adapted from FCN-8s).\n","        wideresnet = models.wide_resnet50_2(pretrained=pretrained, progress=False)\n","\n","        if pretrained:\n","            self.init = nn.Sequential(\n","                wideresnet.conv1,\n","                wideresnet.bn1,\n","                wideresnet.relu,\n","                wideresnet.maxpool\n","            )\n","        else:\n","            self.init = nn.Sequential(\n","                nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","                wideresnet.bn1,\n","                wideresnet.relu,\n","                wideresnet.maxpool\n","            )\n","        self.layer1 = wideresnet.layer1\n","        self.layer2 = wideresnet.layer2\n","        self.layer3 = wideresnet.layer3\n","        self.layer4 = wideresnet.layer4\n","        \n","        if self.skip:\n","            \n","            if hidden_classes is None:\n","                self.classifier1 = nn.Sequential(\n","                    nn.Conv2d(2048 + 256, 64, kernel_size=3, padding=1),\n","                    nn.BatchNorm2d(64),\n","                    nn.ReLU(),\n","                    nn.Dropout2d(0.5),\n","                )\n","                self.final = nn.Conv2d(64, num_classes, kernel_size=3, padding=1)\n","            else:\n","                self.classifier1 = nn.Sequential(\n","                    nn.Conv2d(2048 + 256, 64, kernel_size=3, padding=1),\n","                    nn.BatchNorm2d(64),\n","                    nn.ReLU(),\n","                    nn.Dropout2d(0.5),\n","                )\n","                self.final = nn.Conv2d(64, num_classes - len(hidden_classes), kernel_size=3, padding=1)\n","                \n","        else:\n","\n","            if hidden_classes is None:\n","                self.classifier1 = nn.Sequential(\n","                    nn.Conv2d(2048, 64, kernel_size=3, padding=1),\n","                    nn.BatchNorm2d(64),\n","                    nn.ReLU(),\n","                    nn.Dropout2d(0.5),\n","                )\n","                self.final = nn.Conv2d(64, num_classes, kernel_size=3, padding=1)\n","            else:\n","                self.classifier1 = nn.Sequential(\n","                    nn.Conv2d(2048, 64, kernel_size=3, padding=1),\n","                    nn.BatchNorm2d(64),\n","                    nn.ReLU(),\n","                    nn.Dropout2d(0.5),\n","                )\n","                self.final = nn.Conv2d(64, num_classes - len(hidden_classes), kernel_size=3, padding=1)\n","        \n","        if not pretrained:\n","            initialize_weights(self)\n","        else:\n","            initialize_weights(self.classifier1)\n","            initialize_weights(self.final)\n","\n","    def forward(self, x, feat=False):\n","        \n","        if self.skip:\n","            \n","            # Forward on FCN with Skip Connections.\n","            fv_init = self.init(x)\n","            fv1 = self.layer1(fv_init)\n","            fv2 = self.layer2(fv1)\n","            fv3 = self.layer3(fv2)\n","            fv4 = self.layer4(fv3)\n","            \n","            fv_final = torch.cat([F.upsample(fv1, x.size()[2:], mode='bilinear'),\n","                                  F.upsample(fv4, x.size()[2:], mode='bilinear')], 1)\n","            \n","        else:\n","            \n","            # Forward on FCN without Skip Connections.\n","            fv_init = self.init(x)\n","            fv1 = self.layer1(fv_init)\n","            fv2 = self.layer2(fv1)\n","            fv3 = self.layer3(fv2)\n","            fv4 = self.layer4(fv3)\n","            \n","            fv_final = F.upsample(fv4, x.size()[2:], mode='bilinear')\n","            \n","        classif1 = self.classifier1(fv_final)\n","        output = self.final(classif1)\n","        \n","        if feat:\n","            return (output, classif1, F.upsample(fv2, x.size()[2:], mode='bilinear'))\n","        else:\n","            return output"],"metadata":{"id":"qyayGbsc53Xc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FCNDenseNet121(nn.Module):\n","    \n","    def __init__(self, input_channels, num_classes, pretrained=True, skip=True, hidden_classes=None):\n","\n","        super(FCNDenseNet121, self).__init__()\n","\n","        self.skip = skip\n","        \n","        # DenseNet with Skip Connections (adapted from FCN-8s).\n","        densenet = models.densenet121(pretrained=pretrained, progress=False)\n","\n","        if pretrained:\n","            self.init = densenet.features[:4]\n","        else:\n","            self.init = nn.Sequential(\n","                nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","                nn.BatchNorm2d(64),\n","                nn.ReLU(inplace=True),\n","                nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","            )\n","        self.dense1 = densenet.features[4:6]\n","        self.dense2 = densenet.features[6:8]\n","        self.dense3 = densenet.features[8:10]\n","        self.dense4 = densenet.features[10:12]\n","        \n","        if self.skip:\n","            \n","            if hidden_classes is None:\n","                self.classifier1 = nn.Sequential(\n","                    nn.Conv2d(1024 + 256, 64, kernel_size=3, padding=1),\n","                    nn.BatchNorm2d(64),\n","                    nn.ReLU(),\n","                    nn.Dropout2d(0.5),\n","                )\n","                self.final = nn.Conv2d(64, num_classes, kernel_size=3, padding=1)\n","            else:\n","                self.classifier1 = nn.Sequential(\n","                    nn.Conv2d(1024 + 256, 64, kernel_size=3, padding=1),\n","                    nn.BatchNorm2d(64),\n","                    nn.ReLU(),\n","                    nn.Dropout2d(0.5),\n","                )\n","                self.final = nn.Conv2d(64, num_classes - len(hidden_classes), kernel_size=3, padding=1)\n","                \n","        else:\n","\n","            if hidden_classes is None:\n","                self.classifier1 = nn.Sequential(\n","                    nn.Conv2d(1024, 64, kernel_size=3, padding=1),\n","                    nn.BatchNorm2d(64),\n","                    nn.ReLU(),\n","                    nn.Dropout2d(0.5),\n","                )\n","                self.final = nn.Conv2d(64, num_classes, kernel_size=3, padding=1)\n","            else:\n","                self.classifier1 = nn.Sequential(\n","                    nn.Conv2d(1024, 64, kernel_size=3, padding=1),\n","                    nn.BatchNorm2d(64),\n","                    nn.ReLU(),\n","                    nn.Dropout2d(0.5),\n","                )\n","                self.final = nn.Conv2d(64, num_classes - len(hidden_classes), kernel_size=3, padding=1)\n","        \n","        if not pretrained:\n","            initialize_weights(self)\n","        else:\n","            initialize_weights(self.classifier1)\n","            initialize_weights(self.final)\n","            \n","\n","    def forward(self, x, feat=False):\n","        \n","        if self.skip:\n","            \n","            # Forward on FCN with Skip Connections.\n","            fv_init = self.init(x)\n","            fv1 = self.dense1(fv_init)\n","            fv2 = self.dense2(fv1)\n","            fv3 = self.dense3(fv2)\n","            fv4 = self.dense4(fv3)\n","\n","            fv_final = torch.cat([F.upsample(fv2, x.size()[2:], mode='bilinear'),\n","                                  F.upsample(fv4, x.size()[2:], mode='bilinear')], 1)\n","\n","        else:\n","\n","            # Forward on FCN without Skip Connections.\n","            fv_init = self.init(x)\n","            fv1 = self.dense1(fv_init)\n","            fv2 = self.dense2(fv1)\n","            fv3 = self.dense3(fv2)\n","            fv4 = self.dense4(fv3)\n","\n","            fv_final = F.upsample(fv4, x.size()[2:], mode='bilinear')\n","\n","        classif1 = self.classifier1(fv_final)\n","        output = self.final(classif1)\n","        \n","        if feat:\n","            return (output, classif1, F.upsample(fv2, x.size()[2:], mode='bilinear'))\n","\n","        else:\n","            return output"],"metadata":{"id":"hI_k2LFlplbC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Misc"],"metadata":{"id":"mzJJvRw_Xs7t"}},{"cell_type":"code","source":["from math import ceil\n","\n","def check_mkdir(dir_name):\n","    if not os.path.exists(dir_name):\n","        os.mkdir(dir_name)\n","\n","\n","def initialize_weights(*models):\n","    for model in models:\n","        for module in model.modules():\n","#             if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n","            if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.Linear):\n","                nn.init.kaiming_normal_(module.weight)\n","                if module.bias is not None:\n","                    module.bias.data.zero_()\n","            elif isinstance(module, nn.BatchNorm2d):\n","                module.weight.data.fill_(1)\n","                module.bias.data.zero_()\n","\n","\n","def get_upsampling_weight(in_channels, out_channels, kernel_size):\n","    factor = (kernel_size + 1) // 2\n","    if kernel_size % 2 == 1:\n","        center = factor - 1\n","    else:\n","        center = factor - 0.5\n","    og = np.ogrid[:kernel_size, :kernel_size]\n","    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n","    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype=np.float64)\n","    weight[range(in_channels), range(out_channels), :, :] = filt\n","    return torch.from_numpy(weight).float()\n","\n"],"metadata":{"id":"XoHHAhJqKU55"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class unknownClassifier(nn.Module):\n","    \n","    def __init__(self, in_channels):\n","        super(unknownClassifier, self).__init__()\n","        # output classes in, out\n","        self.dimr = nn.Conv2d(in_channels, 2, kernel_size=1)\n","    \n","    def forward(self, x):\n","        out = self.dimr(x)\n","        return out\n"],"metadata":{"id":"6DVJdf673x7_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CrossEntropyLoss2d(nn.Module):\n","    def __init__(self, weight=None, size_average=True, ignore_index=-1):\n","        super(CrossEntropyLoss2d, self).__init__()\n","        self.nll_loss = nn.NLLLoss(weight, ignore_index=ignore_index, reduction='mean')\n","\n","    def forward(self, inputs, targets):\n","    \t#print(inputs.shape)\n","        return self.nll_loss(F.log_softmax(inputs, dim = 1), targets)\n"],"metadata":{"id":"vnCSIkTd19_t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def initialize_weights(*models):\n","    for model in models:\n","        for module in model.modules():\n","#             if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n","            if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.Linear):\n","                nn.init.kaiming_normal_(module.weight)\n","                if module.bias is not None:\n","                    module.bias.data.zero_()\n","            elif isinstance(module, nn.BatchNorm2d):\n","                module.weight.data.fill_(1)\n","                module.bias.data.zero_()\n"],"metadata":{"id":"uBA38XvL6DAy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Train function"],"metadata":{"id":"DPN36xn2Xm-E"}},{"cell_type":"code","source":["def train(train_loader, net, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, hidden, args):\n","\n","    # Setting network for training mode.\n","    net.train()\n","\n","    # Average Meter for batch loss.\n","    train_loss = list()\n","\n","    # Iterating over batches.\n","    for i, data in enumerate(train_loader):\n","        \n","        # Obtaining images, labels and paths for batch.\n","        inps, labs, true, img_name = data\n","        \n","        # Casting tensors to cuda.\n","        inps, labs, true = inps.to(DEVICE), labs.to(DEVICE), true.to(DEVICE)\n","        \n","        # Casting to cuda variables.\n","        inps = Variable(inps).to(DEVICE)\n","        labs = Variable(labs).to(DEVICE)\n","        true = Variable(true).to(DEVICE)\n","        \n","        # Clears the gradients of optimizer.\n","        optimizer.zero_grad()\n","        \n","        # Forwarding.\n","        outs = net(inps)\n","        soft_outs = F.softmax(outs, dim=1)\n","        \n","        # Obtaining predictions.\n","        prds = soft_outs.data.max(1)[1]\n","        \n","        # Computing loss.\n","        loss = criterion(outs, labs)\n","        \n","        # Computing backpropagation.\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # Appending images for epoch loss calculation.\n","        # prds = prds.squeeze_(1).squeeze_(0).cpu().numpy()\n","        \n","        # inps_np = inps.detach().squeeze(0).cpu().numpy()\n","        # labs_np = labs.detach().squeeze(0).cpu().numpy()\n","        # true_np = true.detach().squeeze(0).cpu().numpy()\n","        \n","        # Updating loss meter.\n","        train_loss.append(loss.data.item())\n","        \n","        # Printing.\n","        if (i + 1) % print_freq == 0:\n","            print('[epoch %d], [iter %d / %d], [train loss %.5f]' % (epoch, i + 1, len(train_loader), np.asarray(train_loss).mean()))\n","            sys.stdout.flush()\n","    \n","    sys.stdout.flush()"],"metadata":{"id":"Vwva9Uxe_jLZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Test function"],"metadata":{"id":"I9CuiDEmXYZn"}},{"cell_type":"code","source":["def test(test_loader, net, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, hidden, args, save_images, save_model):\n","    \n","    # Setting network for evaluation mode.\n","    net.eval()\n","    \n","    with torch.no_grad():\n","        \n","        # Creating output directory.\n","        check_mkdir(os.path.join(outp_path, exp_name, 'epoch_' + str(epoch)))\n","        \n","        # Iterating over batches.\n","        for i, data in enumerate(test_loader):\n","            \n","            print('Test Batch %d/%d' % (i + 1, len(test_loader)))\n","            sys.stdout.flush()\n","            \n","            # Obtaining images, labels and paths for batch.\n","            inps_batch, labs_batch, true_batch, img_name = data\n","            \n","            inps_batch = inps_batch.squeeze()\n","            labs_batch = labs_batch.squeeze()\n","            true_batch = true_batch.squeeze()\n","            \n","            # Iterating over patches inside batch.\n","            for j in range(inps_batch.size(0)): #inps_batch.size(0)\n","                \n","                print('    Test MiniBatch %d/%d' % (j + 1, inps_batch.size(0)))\n","                sys.stdout.flush()\n","                \n","                tic = time.time()\n","                \n","                for k in range(inps_batch.size(1)): #inps_batch.size(1)\n","                    \n","                    inps = inps_batch[j, k].unsqueeze(0)\n","                    labs = labs_batch[j, k].unsqueeze(0)\n","                    true = true_batch[j, k].unsqueeze(0)\n","                    \n","                    # Casting tensors to cuda.\n","                    inps, labs, true = inps.to(DEVICE), labs.to(DEVICE), true.to(DEVICE)\n","                    \n","                    # Casting to cuda variables.\n","                    inps = Variable(inps).to(DEVICE)\n","                    labs = Variable(labs).to(DEVICE)\n","                    true = Variable(true).to(DEVICE)\n","                    \n","                    # Forwarding.\n","                    if conv_name == 'fcnwideresnet50':\n","                        outs, classif1, fv2 = net(inps, feat=True)\n","                    elif conv_name == 'fcndensenet121':\n","                        outs, classif1, fv2 = net(inps, feat=True)\n","                    \n","                    # Computing probabilities.\n","                    soft_outs = F.softmax(outs, dim=1)\n","                    \n","                    # Obtaining prior predictions.\n","                    prds = soft_outs.data.max(1)[1]\n","                    \n","                    # Obtaining posterior predictions.\n","                    # if conv_name == 'fcnwideresnet50':\n","                    #     feat_flat = torch.cat([outs, classif1, fv2], 1)\n","                    # elif conv_name == 'fcndensenet121':\n","                    #     feat_flat = torch.cat([outs, classif1, fv2], 1)\n","                        \n","                    # feat_flat = feat_flat.permute(0, 2, 3, 1).contiguous().view(feat_flat.size(0) * feat_flat.size(2) * feat_flat.size(3), feat_flat.size(1)).cpu().numpy()\n","                    # prds_flat = prds.cpu().numpy().ravel()\n","                    # true_flat = true.cpu().numpy().ravel()\n","                    \n","                    # # Appending images for epoch loss calculation.\n","                    inps_np = inps.detach().squeeze(0).cpu().numpy()\n","                    labs_np = labs.detach().squeeze(0).cpu().numpy()\n","                    true_np = true.detach().squeeze(0).cpu().numpy()\n","                    \n","                    # Saving predictions.\n","                    if (save_images):\n","                        \n","                        # imag_path = os.path.join(outp_path, exp_name, 'epoch_' + str(epoch), img_name[0].replace('.tif', '_img_' + str(j) + '_' + str(k) + '.png'))\n","                        # mask_path = os.path.join(outp_path, exp_name, 'epoch_' + str(epoch), img_name[0].replace('.tif', '_msk_' + str(j) + '_' + str(k) + '.png'))\n","                        # true_path = os.path.join(outp_path, exp_name, 'epoch_' + str(epoch), img_name[0].replace('.tif', '_tru_' + str(j) + '_' + str(k) + '.png'))\n","                        pred_path = os.path.join(outp_path, exp_name, 'epoch_' + str(epoch), img_name[0].replace('.tif', '_prd_' + str(j) + '_' + str(k) + '.png'))\n","                        \n","                        plt.figure(figsize=(16, 6))\n","                        plt.subplot(141)\n","                        plt.title(\"Image\")\n","                        plt.imshow(np.transpose((inps_np[0:3,:,:] + 0.5), (1, 2, 0)))\n","                        plt.subplot(142)\n","                        plt.title(\"Mask\")\n","                        plt.imshow(labs_np, cmap=lab_cmap_1)\n","                        plt.clim(0, 5)\n","                        plt.subplot(143)\n","                        plt.title(\"True Mask\")\n","                        plt.imshow(true_np, cmap=lab_cmap)\n","                        plt.clim(0, 5)\n","                        plt.subplot(144)\n","                        plt.title(\"Prediction\")\n","                        plt.imshow(prds.cpu().squeeze().numpy(), cmap=lab_cmap_1)\n","                        plt.clim(0, 5)\n","                        plt.savefig(pred_path)\n","                        plt.clf()\n","                        plt.close()\n","                        # io.imsave(imag_path, np.transpose(((inps_np[0:3,:,:] + 0.5)*255).astype(np.uint8), (1, 2, 0)))\n","                        # io.imsave(mask_path, util.img_as_ubyte(labs_np.astype(np.uint8)))\n","                        # io.imsave(true_path, util.img_as_ubyte(true_np.astype(np.uint8)))\n","                        # io.imsave(pred_path, util.img_as_ubyte(prds.cpu().squeeze().numpy().astype(np.uint8)))\n","\n","                toc = time.time()\n","                print('        Elapsed Time: %.2f' % (toc - tic))\n","        \n","        sys.stdout.flush()\n","        \n","        if save_model:\n","            \n","            torch.save(net.state_dict(), os.path.join(ckpt_path, exp_name, 'model_' + str(epoch) + '.pth'))\n","            torch.save(optimizer.state_dict(), os.path.join(ckpt_path, exp_name, 'opt_' + str(epoch) + '.pth'))"],"metadata":{"id":"gwW16u5V_j11"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def testmodel(test_loader, net, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, hidden, args, save_images, save_model):\n","    \n","    # Setting network for evaluation mode.\n","    net.eval()\n","    \n","    with torch.no_grad():\n","        \n","        # Creating output directory.\n","        check_mkdir(os.path.join(outp_path, exp_name, 'epoch_' + str(epoch)))\n","        loss = []\n","        totbatches = len(test_loader)\n","        # Iterating over batches.\n","        for i, data in enumerate(test_loader):\n","            \n","            print('Test Batch %d/%d' % (i + 1, len(test_loader)))\n","            sys.stdout.flush()\n","            \n","            # Obtaining images, labels and paths for batch.\n","            inps_batch, labs_batch, true_batch, img_name = data\n","            \n","            inps_batch = inps_batch.squeeze()\n","            labs_batch = labs_batch.squeeze()\n","            true_batch = true_batch.squeeze()\n","            \n","            minibatch_loss = 0\n","            # Iterating over patches inside batch.\n","            for j in range(inps_batch.size(0)):\n","                \n","                print('    Test MiniBatch %d/%d' % (j + 1, inps_batch.size(0)))\n","                sys.stdout.flush()\n","                \n","                tic = time.time()\n","                \n","                for k in range(inps_batch.size(1)):\n","                    \n","                    inps = inps_batch[j, k].unsqueeze(0)\n","                    labs = labs_batch[j, k].unsqueeze(0)\n","                    true = true_batch[j, k].unsqueeze(0)\n","                    \n","                    # Casting tensors to cuda.\n","                    inps, labs, true = inps.to(DEVICE), labs.to(DEVICE), true.to(DEVICE)\n","                    \n","                    # Casting to cuda variables.\n","                    inps = Variable(inps).to(DEVICE)\n","                    labs = Variable(labs).to(DEVICE)\n","                    true = Variable(true).to(DEVICE)\n","                    \n","                    # Forwarding.\n","                    if conv_name == 'fcnwideresnet50':\n","                        outs, classif1, fv2 = net(inps, feat=True)\n","                    elif conv_name == 'fcndensenet121':\n","                        outs, classif1, fv2 = net(inps, feat=True)\n","                    \n","                    # Computing probabilities.\n","                    soft_outs = F.softmax(outs, dim=1)\n","                    \n","                    # Obtaining prior predictions.\n","                    prds = soft_outs.data.max(1)[1]\n","                    \n","                    lossa = criterion(outs, labs)\n","                    minibatch_loss += lossa.data.item()\n","\n","                    # Obtaining posterior predictions.\n","                    # if conv_name == 'fcnwideresnet50':\n","                    #     feat_flat = torch.cat([outs, classif1, fv2], 1)\n","                    # elif conv_name == 'fcndensenet121':\n","                    #     feat_flat = torch.cat([outs, classif1, fv2], 1)\n","                        \n","                    # feat_flat = feat_flat.permute(0, 2, 3, 1).contiguous().view(feat_flat.size(0) * feat_flat.size(2) * feat_flat.size(3), feat_flat.size(1)).cpu().numpy()\n","                    # prds_flat = prds.cpu().numpy().ravel()\n","                    # true_flat = true.cpu().numpy().ravel()\n","                    \n","                    # # Appending images for epoch loss calculation.\n","                    # inps_np = inps.detach().squeeze(0).cpu().numpy()\n","                    # labs_np = labs.detach().squeeze(0).cpu().numpy()\n","                    # true_np = true.detach().squeeze(0).cpu().numpy()\n","                    \n","                    # # Saving predictions.\n","                    # if (save_images):\n","                        \n","                    #     imag_path = os.path.join(outp_path, exp_name, 'epoch_' + str(epoch), img_name[0].replace('.tif', '_img_' + str(j) + '_' + str(k) + '.png'))\n","                    #     mask_path = os.path.join(outp_path, exp_name, 'epoch_' + str(epoch), img_name[0].replace('.tif', '_msk_' + str(j) + '_' + str(k) + '.png'))\n","                    #     true_path = os.path.join(outp_path, exp_name, 'epoch_' + str(epoch), img_name[0].replace('.tif', '_tru_' + str(j) + '_' + str(k) + '.png'))\n","                    #     pred_path = os.path.join(outp_path, exp_name, 'epoch_' + str(epoch), img_name[0].replace('.tif', '_prd_' + str(j) + '_' + str(k) + '.png'))\n","                        \n","                    #     io.imsave(imag_path, np.transpose(inps_np, (1, 2, 0)))\n","                    #     io.imsave(mask_path, util.img_as_ubyte(labs_np))\n","                    #     io.imsave(true_path, util.img_as_ubyte(true_np))\n","                    #     io.imsave(pred_path, util.img_as_ubyte(prds.cpu().squeeze().numpy()))\n","                \n","                toc = time.time()\n","                print('        Elapsed Time: %.2f' % (toc - tic))\n","\n","            loss.append(minibatch_loss/inps_batch.size(0))\n","            print('Batch loss = %.2f', loss[-1])\n","\n","        sys.stdout.flush()\n","        print('Test loss: %.2f', np.asarray(loss).mean())\n","        \n","        if save_model:\n","            \n","            torch.save(net.state_dict(), os.path.join(ckpt_path, exp_name, 'model_' + str(epoch) + '.pth'))\n","            torch.save(optimizer.state_dict(), os.path.join(ckpt_path, exp_name, 'opt_' + str(epoch) + '.pth'))"],"metadata":{"id":"x85lXDVVvCDh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Functioning"],"metadata":{"id":"S28YZi6IXdvr"}},{"cell_type":"code","source":["# potsdam\n","lr = 1e-3\n","weight_decay = 5e-6\n","momentum = 0.9\n","batch_size = 1\n","# num_workers = 8\n","print_freq = 1\n","w_size = 224\n","h_size = 224\n","input_channels = 4\n","num_classes = 5\n","epoch_num = 600\n","test_freq = 600\n","save_freq = 600\n","num_workers = 1\n","conv_name = 'fcndensenet121'\n","args = f'lr:{lr}, weight_decay:{weight_decay} momentum:{momentum} batch_size:{batch_size} num_workers:{num_workers} print_freq:{print_freq} \\\n","        w_size:{w_size} h_size:{h_size} input_channels:{input_channels} num_classes:{num_classes} epoch_num:{epoch_num} test_freq:{test_freq} \\\n","        save_freq:{save_freq} conv_name:{conv_name}'"],"metadata":{"id":"egcNhdsyvKEc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["HiddenClasses = [1]\n","num_known_classes = num_classes - len(HiddenClasses)\n","num_unknown_classes = len(HiddenClasses)\n","weights = [1.0 for i in range(num_known_classes)]\n","weights = torch.FloatTensor(weights)\n","DEVICE = 'cuda'"],"metadata":{"id":"AUEHZZ9zemZ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hidden class Nil\n","traindata = ListDataset(potsdam, 'Potsdam', 'Train', (h_size, w_size), hidden_classes=HiddenClasses, overlap=False, use_dsm=True)\n","trainloader = DataLoader(traindata, batch_size=None, num_workers=num_workers, shuffle=True)\n","\n","valdata = ListDataset(potsdam, 'Potsdam', 'Val', (h_size, w_size), hidden_classes=HiddenClasses, overlap=True, use_dsm=True)\n","valloader = DataLoader(valdata, batch_size=1, num_workers=0, shuffle=True)\n","\n","testdata = ListDataset(potsdam, 'Potsdam', 'Test', (h_size, w_size), hidden_classes=HiddenClasses, overlap=True, use_dsm=True)\n","testloader = DataLoader(testdata, batch_size=1, num_workers=0, shuffle=True)"],"metadata":{"id":"TzZDv-uckcfp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert(msk):\n","    msk = msk.astype(np.int64)\n","    new = np.zeros((msk.shape[0], msk.shape[1]), dtype=np.int64)\n","    \n","    msk = msk // 255\n","    msk = msk * (1, 7, 49)\n","    msk = msk.sum(axis=2)\n","\n","    new[msk == 1 + 7 + 49] = 0 # Street.\n","    new[msk ==         49] = 1 # Building.\n","    new[msk ==     7 + 49] = 2 # Grass.\n","    new[msk ==     7     ] = 3 # Tree.\n","    new[msk == 1 + 7     ] = 4 # Car.\n","    new[msk == 1         ] = 5 # Surfaces.\n","    new[msk == 0         ] = 6 # Boundaries.\n","\n","    return new"],"metadata":{"id":"P9p2Ah6ijhq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from matplotlib import colors\n","'''\n","Vaihingen/Potsdam classes:\n","    0 = Street\n","    1 = Building\n","    2 = Grass\n","    3 = Tree\n","    4 = Car\n","    5 = Surfaces\n","    6 = Unknown\n","'''\n","# no hidden class cmap\n","cmap_list = [\n","    (1.0, 1.0, 1.0, 1.0), # street. \n","    (0.0, 0.0, 1.0, 1.0), # Building\n","    (0.0, 1.0, 1.0, 1.0), # Grass.\n","    (0.0, 1.0, 0.0, 1.0), # Tree.\n","    (1.0, 1.0, 0.0, 1.0), # Car.\n","    (1.0, 0.0, 0.0, 1.0),  # surfaces\n","    (1.0, 0.0, 1.0, 1.0), # Unknown.\n","]\n","lab_cmap = colors.ListedColormap(cmap_list)"],"metadata":{"id":"LsRoM5SkGyvb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cmap_list_1 = [\n","    (1.0, 1.0, 1.0, 1.0), # street.\n","    (0.0, 1.0, 1.0, 1.0), # Grass.\n","    (0.0, 1.0, 0.0, 1.0), # Tree.\n","    (1.0, 1.0, 0.0, 1.0), # Car.\n","    (1.0, 0.0, 0.0, 1.0),  # surfaces       \n","    (0.0, 0.0, 1.0, 1.0), # Building  \n","    # (0.0, 0.0, 0.0, 1.0), # Boundaries (if present).\n","]\n","lab_cmap_1 = colors.ListedColormap(cmap_list_1)"],"metadata":{"id":"mYaD5QMosrqU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img, msk, msk_true, spl = valdata[0]\n","a = 0\n","b = 29#np.random.randint(30)\n","plt.subplot(131)\n","plt.title(\"Image\")\n","plt.imshow(img[a, b, :3, :, :].permute(1, 2, 0)+0.5)\n","plt.subplot(132)\n","plt.title(\"Mask\")\n","plt.imshow(msk[a, b, :, :], cmap=lab_cmap_1)\n","plt.clim(0, 5)\n","plt.subplot(133)\n","plt.title(\"True Mask\")\n","plt.imshow(msk_true[a, b, :, :], cmap=lab_cmap)\n","plt.clim(0, 5)\n","# plt.subplot(144)\n","# plt.title(\"Prediction\")\n","# plt.imshow(prds.cpu().squeeze().numpy(), cmap=lab_cmap_1)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"id":"bgKcrVtsy2MD","executionInfo":{"status":"ok","timestamp":1644484420637,"user_tz":-330,"elapsed":11150,"user":{"displayName":"Lalit Saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2-n8dJEtiG1wIVxTx8taU2Q8P-qT6UBMyqOcy=s64","userId":"07496788471592910399"}},"outputId":"2d247e8e-b6e3-48b5-c25b-1ce4b89c2a2e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 3 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["print(msk[a, b, 200, 50], msk_true[a, b, 200, 50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EXAQnuRAUYUU","executionInfo":{"status":"ok","timestamp":1644484420638,"user_tz":-330,"elapsed":9,"user":{"displayName":"Lalit Saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2-n8dJEtiG1wIVxTx8taU2Q8P-qT6UBMyqOcy=s64","userId":"07496788471592910399"}},"outputId":"8199d6b6-05fa-4c5d-91e9-3370b21ffef6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(5) tensor(1)\n"]}]},{"cell_type":"code","source":["outp_path = '/content/drive/MyDrive/BTPII/outputs'\n","ckpt_path = '/content/drive/MyDrive/BTPII/checkpoints'\n","exp_name = 'hc_0_exp2'\n","best_record = {'epoch': 0, 'lr': 1e-4, 'val_loss': 1e10, 'acc': 0, 'acc_cls': 0, 'iou': 0}"],"metadata":{"id":"k_BHks--cXSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TnhkKG3YXJcC","executionInfo":{"status":"ok","timestamp":1644484420638,"user_tz":-330,"elapsed":6,"user":{"displayName":"Lalit Saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2-n8dJEtiG1wIVxTx8taU2Q8P-qT6UBMyqOcy=s64","userId":"07496788471592910399"}},"outputId":"cc3796e8-6cba-4fb6-f08a-9aa0fb86f922"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","source":["# model = FCNWideResNet50(input_channels, num_classes, pretrained=False, skip=True, hidden_classes=HiddenClasses).to(DEVICE)\n","model = FCNDenseNet121(input_channels, num_classes, pretrained=False, skip=True, hidden_classes=HiddenClasses).to(DEVICE)\n","criterion = CrossEntropyLoss2d(weight=weights, size_average=False, ignore_index=num_classes).to(DEVICE)\n","# criterion = nn.CrossEntropyLoss(weight=weights, size_average=False, ignore_index=num_classes).to(DEVICE)\n","optimizer = torch.optim.Adam([param for name, param in model.named_parameters() if name[-4:] == 'bias'], lr=lr, weight_decay=weight_decay, betas=(momentum, 0.99))\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, epoch_num//3, 0.2)\n","\n","check_mkdir(ckpt_path)\n","check_mkdir(os.path.join(ckpt_path, exp_name))\n","check_mkdir(outp_path)\n","check_mkdir(os.path.join(outp_path, exp_name))"],"metadata":{"id":"IbwXdu6KQSln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model.load_state_dict(torch.load(os.path.join(ckpt_path, exp_name, 'model_33.pth')))\n","model.load_state_dict(torch.load(os.path.join(potsdam, 'model_600.pth')))\n","model.eval()"],"metadata":{"id":"XxZu3cD2VYSR","executionInfo":{"status":"ok","timestamp":1644484423567,"user_tz":-330,"elapsed":8,"user":{"displayName":"Lalit Saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2-n8dJEtiG1wIVxTx8taU2Q8P-qT6UBMyqOcy=s64","userId":"07496788471592910399"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"da2ce1e6-a1cc-43b1-c2c4-0472cf545f4b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FCNDenseNet121(\n","  (init): Sequential(\n","    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (dense1): Sequential(\n","    (denseblock1): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition1): _Transition(\n","      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","  )\n","  (dense2): Sequential(\n","    (denseblock2): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition2): _Transition(\n","      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","  )\n","  (dense3): Sequential(\n","    (denseblock3): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer13): _DenseLayer(\n","        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer14): _DenseLayer(\n","        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer15): _DenseLayer(\n","        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer16): _DenseLayer(\n","        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer17): _DenseLayer(\n","        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer18): _DenseLayer(\n","        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer19): _DenseLayer(\n","        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer20): _DenseLayer(\n","        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer21): _DenseLayer(\n","        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer22): _DenseLayer(\n","        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer23): _DenseLayer(\n","        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer24): _DenseLayer(\n","        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition3): _Transition(\n","      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","  )\n","  (dense4): Sequential(\n","    (denseblock4): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer13): _DenseLayer(\n","        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer14): _DenseLayer(\n","        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer15): _DenseLayer(\n","        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer16): _DenseLayer(\n","        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (classifier1): Sequential(\n","    (0): Conv2d(1280, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout2d(p=0.5, inplace=False)\n","  )\n","  (final): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",")"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["import datetime"],"metadata":{"id":"R_LtonxnU4lU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.backends import cudnn\n","cudnn.benchmark = True"],"metadata":{"id":"Jj2uvn9h0969"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["curr_epoch = 1\n","open(os.path.join(ckpt_path, exp_name, str(datetime.datetime.now()) + '.txt'), 'w').write(args + '\\n\\n')\n","\n","for epoch in range(curr_epoch, epoch_num + 1):\n","\n","    # Training function.\n","    train(trainloader, model, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, HiddenClasses, {})\n","\n","    if epoch % test_freq == 0:\n","            \n","        torch.save(model.state_dict(), os.path.join(ckpt_path, exp_name, 'model_' + str(epoch) + '.pth'))\n","        torch.save(optimizer.state_dict(), os.path.join(ckpt_path, exp_name, 'opt_' + str(epoch) + '.pth'))\n","            \n","            # Computing test.\n","        test(valloader, model, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, HiddenClasses, {}, True, True) #epoch % args['save_freq'] == 0)\n","        \n","    scheduler.step()        \n","    print('Exiting...')"],"metadata":{"id":"Tu_DHtK0Kvmv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model.state_dict(), os.path.join(ckpt_path, exp_name, 'model_' + str(epoch) + '.pth'))\n","torch.save(optimizer.state_dict(), os.path.join(ckpt_path, exp_name, 'opt_' + str(epoch) + '.pth'))"],"metadata":{"id":"rz3yF_V1djlf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epoch = 600"],"metadata":{"id":"KZfo6RFSwAPc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testmodel(valloader, model, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, HiddenClasses, {}, True, False)"],"metadata":{"id":"7fabijUW2VAc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0675c2fc-93c5-4d3b-ec22-e6409556000b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Batch 1/6\n","    Test MiniBatch 1/53\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode)\n"]},{"output_type":"stream","name":"stdout","text":["        Elapsed Time: 14.16\n","    Test MiniBatch 2/53\n","        Elapsed Time: 6.41\n","    Test MiniBatch 3/53\n","        Elapsed Time: 6.42\n","    Test MiniBatch 4/53\n","        Elapsed Time: 6.41\n","    Test MiniBatch 5/53\n","        Elapsed Time: 6.47\n","    Test MiniBatch 6/53\n","        Elapsed Time: 6.47\n","    Test MiniBatch 7/53\n","        Elapsed Time: 6.73\n","    Test MiniBatch 8/53\n","        Elapsed Time: 6.47\n","    Test MiniBatch 9/53\n","        Elapsed Time: 6.45\n","    Test MiniBatch 10/53\n","        Elapsed Time: 6.51\n","    Test MiniBatch 11/53\n","        Elapsed Time: 6.50\n","    Test MiniBatch 12/53\n","        Elapsed Time: 6.50\n","    Test MiniBatch 13/53\n","        Elapsed Time: 6.50\n","    Test MiniBatch 14/53\n","        Elapsed Time: 6.51\n","    Test MiniBatch 15/53\n","        Elapsed Time: 6.51\n","    Test MiniBatch 16/53\n","        Elapsed Time: 6.51\n","    Test MiniBatch 17/53\n","        Elapsed Time: 6.49\n","    Test MiniBatch 18/53\n","        Elapsed Time: 6.53\n","    Test MiniBatch 19/53\n","        Elapsed Time: 6.52\n","    Test MiniBatch 20/53\n","        Elapsed Time: 6.49\n","    Test MiniBatch 21/53\n","        Elapsed Time: 6.52\n","    Test MiniBatch 22/53\n","        Elapsed Time: 6.51\n","    Test MiniBatch 23/53\n","        Elapsed Time: 6.53\n","    Test MiniBatch 24/53\n","        Elapsed Time: 6.50\n","    Test MiniBatch 25/53\n","        Elapsed Time: 6.49\n","    Test MiniBatch 26/53\n","        Elapsed Time: 6.48\n","    Test MiniBatch 27/53\n","        Elapsed Time: 6.50\n","    Test MiniBatch 28/53\n","        Elapsed Time: 6.52\n","    Test MiniBatch 29/53\n","        Elapsed Time: 6.51\n","    Test MiniBatch 30/53\n","        Elapsed Time: 6.51\n","    Test MiniBatch 31/53\n","        Elapsed Time: 6.54\n","    Test MiniBatch 32/53\n","        Elapsed Time: 6.52\n","    Test MiniBatch 33/53\n","        Elapsed Time: 6.50\n","    Test MiniBatch 34/53\n","        Elapsed Time: 6.50\n","    Test MiniBatch 35/53\n","        Elapsed Time: 6.53\n","    Test MiniBatch 36/53\n","        Elapsed Time: 6.53\n","    Test MiniBatch 37/53\n","        Elapsed Time: 6.53\n","    Test MiniBatch 38/53\n","        Elapsed Time: 6.51\n","    Test MiniBatch 39/53\n","        Elapsed Time: 6.50\n","    Test MiniBatch 40/53\n","        Elapsed Time: 6.53\n","    Test MiniBatch 41/53\n","        Elapsed Time: 6.50\n","    Test MiniBatch 42/53\n","        Elapsed Time: 6.52\n","    Test MiniBatch 43/53\n","        Elapsed Time: 6.51\n","    Test MiniBatch 44/53\n","        Elapsed Time: 6.51\n","    Test MiniBatch 45/53\n","        Elapsed Time: 6.50\n","    Test MiniBatch 46/53\n","        Elapsed Time: 6.52\n","    Test MiniBatch 47/53\n","        Elapsed Time: 6.49\n","    Test MiniBatch 48/53\n","        Elapsed Time: 6.51\n","    Test MiniBatch 49/53\n","        Elapsed Time: 6.51\n","    Test MiniBatch 50/53\n","        Elapsed Time: 6.52\n","    Test MiniBatch 51/53\n","        Elapsed Time: 6.50\n","    Test MiniBatch 52/53\n","        Elapsed Time: 6.50\n","    Test MiniBatch 53/53\n","        Elapsed Time: 6.50\n","Batch loss = %.2f 60.92978980887093\n"]}]}]}