{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenSetSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_Of24jjSXv8s",
        "mzJJvRw_Xs7t",
        "DPN36xn2Xm-E"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fxk4Gu1ZUYQt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "import sys\n",
        "from skimage import io\n",
        "from skimage import color\n",
        "from skimage import transform\n",
        "from skimage import util\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as album \n",
        "from torch.autograd import Variable\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "iD_AkmqPXWJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "potsdam = \"/content/drive/MyDrive/BTPII/Potsdam\""
      ],
      "metadata": {
        "id": "TadRerCahTuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Custom Dataset"
      ],
      "metadata": {
        "id": "eascsvurX7jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ListDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, root, dataset, mode, crop_size, normalization='minmax', hidden_classes=None, overlap=False, use_dsm=False):\n",
        "\n",
        "        # Initializing variables.\n",
        "        self.root = root\n",
        "        self.dataset = dataset\n",
        "        self.mode = mode\n",
        "        self.crop_size = crop_size\n",
        "        self.normalization = normalization\n",
        "        self.hidden_classes = hidden_classes\n",
        "        self.overlap = overlap\n",
        "        self.use_dsm = use_dsm\n",
        "        \n",
        "        self.num_classes = 6 # For Vaihingen and Potsdam.\n",
        "            \n",
        "        if self.hidden_classes is not None:\n",
        "            self.n_classes = self.num_classes - len(hidden_classes)\n",
        "        else:\n",
        "            self.n_classes = self.num_classes\n",
        "\n",
        "        # Creating list of paths.\n",
        "        self.imgs = self.make_dataset()\n",
        "\n",
        "        # Check for consistency in list.\n",
        "        if len(self.imgs) == 0:\n",
        "\n",
        "            raise (RuntimeError('Found 0 images, please check the data set'))\n",
        "\n",
        "    def make_dataset(self):\n",
        "\n",
        "        # Making sure the mode is correct.\n",
        "        assert self.mode in ['Train', 'Test', 'Val']\n",
        "\n",
        "        # Setting string for the mode.\n",
        "        img_dir = os.path.join(self.root, self.mode, 'Images')\n",
        "        msk_dir = os.path.join(self.root, self.mode, 'Masks')\n",
        "        if self.use_dsm:\n",
        "            dsm_dir = os.path.join(self.root, self.mode, 'NDSM')\n",
        "\n",
        "        # if self.mode == 'Val':\n",
        "        #     img_dir = os.path.join(self.root, 'Train', 'Images')\n",
        "        #     msk_dir = os.path.join(self.root, 'Train', 'Masks')\n",
        "        #     if self.use_dsm:\n",
        "        #         dsm_dir = os.path.join(self.root, 'Train', 'NDSM')\n",
        "\n",
        "        data_list = sorted([f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))])\n",
        "\n",
        "        # Creating list containing image and ground truth paths.\n",
        "        items = []\n",
        "        if self.dataset == 'Vaihingen':\n",
        "            for it in data_list:\n",
        "                item = (\n",
        "                    os.path.join(img_dir, it),\n",
        "                    os.path.join(msk_dir, it),\n",
        "                    # os.path.join(dsm_dir, it.replace('top_mosaic_09cm_area', 'dsm_09cm_matching_area').replace('.tif', '_normalized.jpg'))\n",
        "                )\n",
        "                items.append(item)\n",
        "        elif self.dataset == 'Potsdam':\n",
        "            for it in data_list:\n",
        "                if self.use_dsm:\n",
        "                    item = (\n",
        "                        os.path.join(img_dir, it),\n",
        "                        os.path.join(msk_dir, it.replace('_IRRG.tif', '_label.tif')),\n",
        "                        # os.path.join(msk_dir, it.replace('_IRRG.tif', '_label_noBoundary.tif')),\n",
        "                        os.path.join(dsm_dir, it.replace('top_potsdam_', 'dsm_potsdam_').replace('_IRRG.tif', '_normalized_lastools.jpg'))\n",
        "                    )\n",
        "                else:\n",
        "                    item = (\n",
        "                        os.path.join(img_dir, it),\n",
        "                        os.path.join(msk_dir, it.replace('_IRRG.tif', '_label.tif')),\n",
        "                        # os.path.join(msk_dir, it.replace('_IRRG.tif', '_label_noBoundary.tif')),\n",
        "                        # os.path.join(dsm_dir, it.replace('top_potsdam_', 'dsm_potsdam_').replace('_IRRG.tif', '_normalized_lastools.jpg'))\n",
        "                    )\n",
        "                items.append(item)\n",
        "        \n",
        "        # Returning list.\n",
        "        return items\n",
        "    \n",
        "    def random_crops(self, img, msk, msk_true, n_crops):\n",
        "        \n",
        "        img_crop_list = []\n",
        "        msk_crop_list = []\n",
        "        msk_true_crop_list = []\n",
        "        \n",
        "        rand_fliplr = np.random.random() > 0.50\n",
        "        rand_flipud = np.random.random() > 0.50\n",
        "        rand_rotate = np.random.random()\n",
        "        \n",
        "        for i in range(n_crops):\n",
        "            \n",
        "            rand_y = np.random.randint(msk.shape[0] - self.crop_size[0])\n",
        "            rand_x = np.random.randint(msk.shape[1] - self.crop_size[1])\n",
        "\n",
        "            img_patch = img[rand_y:(rand_y + self.crop_size[0]),\n",
        "                            rand_x:(rand_x + self.crop_size[1])]\n",
        "            msk_patch = msk[rand_y:(rand_y + self.crop_size[0]),\n",
        "                            rand_x:(rand_x + self.crop_size[1])]\n",
        "            msk_true_patch = msk_true[rand_y:(rand_y + self.crop_size[0]),\n",
        "                                      rand_x:(rand_x + self.crop_size[1])]\n",
        "            \n",
        "            if rand_fliplr:\n",
        "                img_patch = np.fliplr(img_patch)\n",
        "                msk_patch = np.fliplr(msk_patch)\n",
        "                msk_true_patch = np.fliplr(msk_true_patch)\n",
        "            if rand_flipud:\n",
        "                img_patch = np.flipud(img_patch)\n",
        "                msk_patch = np.flipud(msk_patch)\n",
        "                msk_true_patch = np.flipud(msk_true_patch)\n",
        "            \n",
        "            if rand_rotate < 0.25:\n",
        "                img_patch = transform.rotate(img_patch, 270, order=1, preserve_range=True)\n",
        "                msk_patch = transform.rotate(msk_patch, 270, order=0, preserve_range=True)\n",
        "                msk_true_patch = transform.rotate(msk_true_patch, 270, order=0, preserve_range=True)\n",
        "            elif rand_rotate < 0.50:\n",
        "                img_patch = transform.rotate(img_patch, 180, order=1, preserve_range=True)\n",
        "                msk_patch = transform.rotate(msk_patch, 180, order=0, preserve_range=True)\n",
        "                msk_true_patch = transform.rotate(msk_true_patch, 180, order=0, preserve_range=True)\n",
        "            elif rand_rotate < 0.75:\n",
        "                img_patch = transform.rotate(img_patch, 90, order=1, preserve_range=True)\n",
        "                msk_patch = transform.rotate(msk_patch, 90, order=0, preserve_range=True)\n",
        "                msk_true_patch = transform.rotate(msk_true_patch, 90, order=0, preserve_range=True)\n",
        "                \n",
        "            img_patch = img_patch.astype(np.float32)\n",
        "            msk_patch = msk_patch.astype(np.int64)\n",
        "            msk_true_patch = msk_true_patch.astype(np.int64)\n",
        "            \n",
        "            img_crop_list.append(img_patch)\n",
        "            msk_crop_list.append(msk_patch)\n",
        "            msk_true_crop_list.append(msk_true_patch)\n",
        "        \n",
        "        img = np.asarray(img_crop_list)\n",
        "        msk = np.asarray(msk_crop_list)\n",
        "        msk_true = np.asarray(msk_true_crop_list)\n",
        "        \n",
        "        return img, msk, msk_true\n",
        "        \n",
        "    def test_crops(self, img, msk, msk_true):\n",
        "        \n",
        "        n_channels = 3\n",
        "        if self.use_dsm:\n",
        "            n_channels = 4\n",
        "        if self.overlap:\n",
        "            w_img = util.view_as_windows(img,\n",
        "                                         (self.crop_size[0], self.crop_size[1], n_channels),\n",
        "                                         (self.crop_size[0] // 2, self.crop_size[1] // 2, n_channels)).squeeze()\n",
        "            w_msk = util.view_as_windows(msk,\n",
        "                                         (self.crop_size[0], self.crop_size[1]),\n",
        "                                         (self.crop_size[0] // 2, self.crop_size[1] // 2))\n",
        "            w_msk_true = util.view_as_windows(msk_true,\n",
        "                                              (self.crop_size[0], self.crop_size[1]),\n",
        "                                              (self.crop_size[0] // 2, self.crop_size[1] // 2))\n",
        "        else:\n",
        "            w_img = util.view_as_blocks(img, (self.crop_size[0], self.crop_size[1], n_channels)).squeeze()\n",
        "            w_msk = util.view_as_blocks(msk, (self.crop_size[0], self.crop_size[1]))\n",
        "            w_msk_true = util.view_as_blocks(msk_true, (self.crop_size[0], self.crop_size[1]))\n",
        "        \n",
        "        return w_img, w_msk, w_msk_true\n",
        "        \n",
        "    def shift_labels(self, msk):\n",
        "        \n",
        "        msk_true = np.copy(msk)\n",
        "        \n",
        "        cont = 0\n",
        "        for h_c in self.hidden_classes:\n",
        "            \n",
        "            msk[msk == h_c - cont] = 100\n",
        "            for c in range(h_c - cont + 1, self.num_classes):\n",
        "                msk[msk == c] = c - 1\n",
        "                # msk_true[msk_true == c] = c - 1\n",
        "            cont = cont + 1\n",
        "        \n",
        "        # msk_true[msk == 100] = self.num_classes - len(self.hidden_classes)\n",
        "        msk[msk == 100] = self.num_classes #- len(self.hidden_classes)\n",
        "        \n",
        "        return msk, msk_true\n",
        "    \n",
        "    def mask_to_class(self, msk):\n",
        "    \n",
        "        msk = msk.astype(np.int64)\n",
        "        new = np.zeros((msk.shape[0], msk.shape[1]), dtype=np.int64)\n",
        "        \n",
        "        msk = msk // 255\n",
        "        msk = msk * (1, 7, 49)\n",
        "        msk = msk.sum(axis=2)\n",
        "\n",
        "        new[msk == 1 + 7 + 49] = 0 # Street.\n",
        "        new[msk ==         49] = 1 # Building.\n",
        "        new[msk ==     7 + 49] = 2 # Grass.\n",
        "        new[msk ==     7     ] = 3 # Tree.\n",
        "        new[msk == 1 + 7     ] = 4 # Car.\n",
        "        new[msk == 1         ] = 5 # Surfaces.\n",
        "        new[msk == 0         ] = 6 # Boundaries.\n",
        "\n",
        "        return new\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        # Reading items from list.\n",
        "        if self.use_dsm:\n",
        "            img_path, msk_path, dsm_path = self.imgs[index]\n",
        "        else:\n",
        "            img_path, msk_path = self.imgs[index]\n",
        "        \n",
        "        # Reading images.\n",
        "        img_raw = io.imread(img_path)\n",
        "        msk_raw = io.imread(msk_path)\n",
        "        if self.use_dsm:\n",
        "            dsm_raw = io.imread(dsm_path)\n",
        "            \n",
        "        if len(img_raw.shape) == 2:\n",
        "            img_raw = color.gray2rgb(img_raw)\n",
        "        \n",
        "        if self.use_dsm:\n",
        "            img = np.full((img_raw.shape[0] + self.crop_size[0] - (img_raw.shape[0] % self.crop_size[0]),\n",
        "                           img_raw.shape[1] + self.crop_size[1] - (img_raw.shape[1] % self.crop_size[1]),\n",
        "                           img_raw.shape[2] + 1),\n",
        "                          fill_value=0.0,\n",
        "                          dtype=np.float32)\n",
        "        else:\n",
        "            img = np.full((img_raw.shape[0] + self.crop_size[0] - (img_raw.shape[0] % self.crop_size[0]),\n",
        "                           img_raw.shape[1] + self.crop_size[1] - (img_raw.shape[1] % self.crop_size[1]),\n",
        "                           img_raw.shape[2]),\n",
        "                          fill_value=0.0,\n",
        "                          dtype=np.float32)\n",
        "        \n",
        "        msk = np.full((msk_raw.shape[0] + self.crop_size[0] - (msk_raw.shape[0] % self.crop_size[0]),\n",
        "                       msk_raw.shape[1] + self.crop_size[1] - (msk_raw.shape[1] % self.crop_size[1]),\n",
        "                       msk_raw.shape[2]),\n",
        "                      fill_value=0,\n",
        "                      dtype=np.int64)\n",
        "        \n",
        "        img[:img_raw.shape[0], :img_raw.shape[1], :img_raw.shape[2]] = img_raw\n",
        "        if self.use_dsm:\n",
        "            img[:dsm_raw.shape[0], :dsm_raw.shape[1], -1] = dsm_raw\n",
        "        msk[:msk_raw.shape[0], :msk_raw.shape[1]] = msk_raw\n",
        "        \n",
        "        msk = self.mask_to_class(msk)\n",
        "        \n",
        "        msk, msk_true = self.shift_labels(msk)\n",
        "        \n",
        "        # Normalization.\n",
        "        img = (img / 255) - 0.5\n",
        "        \n",
        "        if self.mode == 'Train':\n",
        "            \n",
        "            img, msk, msk_true = self.random_crops(img, msk, msk_true, 3)\n",
        "            \n",
        "            img = np.transpose(img, (0, 3, 1, 2))\n",
        "        \n",
        "        elif self.mode == 'Val':\n",
        "            \n",
        "            img, msk, msk_true = self.test_crops(img, msk, msk_true)\n",
        "            \n",
        "            img = np.transpose(img, (0, 1, 4, 2, 3))\n",
        "            msk = np.transpose(msk, (0, 1, 2, 3))\n",
        "            msk_true = np.transpose(msk_true, (0, 1, 2, 3))\n",
        "        \n",
        "        elif self.mode == 'Test':\n",
        "            \n",
        "            img, msk, msk_true = self.test_crops(img, msk, msk_true)\n",
        "            \n",
        "            img = np.transpose(img, (0, 1, 4, 2, 3))\n",
        "            msk = np.transpose(msk, (0, 1, 2, 3))\n",
        "            msk_true = np.transpose(msk_true, (0, 1, 2, 3))\n",
        "        \n",
        "        msk[msk == self.num_classes + 1] = self.num_classes\n",
        "        msk_true[msk_true == self.num_classes + 1] = self.num_classes\n",
        "\n",
        "        # Splitting path.\n",
        "        spl = img_path.split('/')\n",
        "\n",
        "        # Turning to tensors.\n",
        "        img = torch.from_numpy(img)\n",
        "        msk = torch.from_numpy(msk)\n",
        "        msk_true = torch.from_numpy(msk_true)\n",
        "\n",
        "        # Returning to iterator.\n",
        "        return img, msk, msk_true, spl[-1]\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "1r0_P2grh17A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FCN Models"
      ],
      "metadata": {
        "id": "_Of24jjSXv8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FCNWideResNet50(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_channels, num_classes, pretrained=True, skip=True, hidden_classes=None):\n",
        "\n",
        "        super(FCNWideResNet50, self).__init__()\n",
        "\n",
        "        self.skip = skip\n",
        "        \n",
        "        # ResNet-50 with Skip Connections (adapted from FCN-8s).\n",
        "        wideresnet = models.wide_resnet50_2(pretrained=pretrained, progress=False)\n",
        "\n",
        "        if pretrained:\n",
        "            self.init = nn.Sequential(\n",
        "                wideresnet.conv1,\n",
        "                wideresnet.bn1,\n",
        "                wideresnet.relu,\n",
        "                wideresnet.maxpool\n",
        "            )\n",
        "        else:\n",
        "            self.init = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                wideresnet.bn1,\n",
        "                wideresnet.relu,\n",
        "                wideresnet.maxpool\n",
        "            )\n",
        "        self.layer1 = wideresnet.layer1\n",
        "        self.layer2 = wideresnet.layer2\n",
        "        self.layer3 = wideresnet.layer3\n",
        "        self.layer4 = wideresnet.layer4\n",
        "        \n",
        "        if self.skip:\n",
        "            \n",
        "            if hidden_classes is None:\n",
        "                self.classifier1 = nn.Sequential(\n",
        "                    nn.Conv2d(2048 + 256, 64, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(64),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout2d(0.5),\n",
        "                )\n",
        "                self.final = nn.Conv2d(64, num_classes, kernel_size=3, padding=1)\n",
        "            else:\n",
        "                self.classifier1 = nn.Sequential(\n",
        "                    nn.Conv2d(2048 + 256, 64, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(64),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout2d(0.5),\n",
        "                )\n",
        "                self.final = nn.Conv2d(64, num_classes - len(hidden_classes), kernel_size=3, padding=1)\n",
        "                \n",
        "        else:\n",
        "\n",
        "            if hidden_classes is None:\n",
        "                self.classifier1 = nn.Sequential(\n",
        "                    nn.Conv2d(2048, 64, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(64),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout2d(0.5),\n",
        "                )\n",
        "                self.final = nn.Conv2d(64, num_classes, kernel_size=3, padding=1)\n",
        "            else:\n",
        "                self.classifier1 = nn.Sequential(\n",
        "                    nn.Conv2d(2048, 64, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(64),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout2d(0.5),\n",
        "                )\n",
        "                self.final = nn.Conv2d(64, num_classes - len(hidden_classes), kernel_size=3, padding=1)\n",
        "        \n",
        "        if not pretrained:\n",
        "            initialize_weights(self)\n",
        "        else:\n",
        "            initialize_weights(self.classifier1)\n",
        "            initialize_weights(self.final)\n",
        "\n",
        "    def forward(self, x, feat=False):\n",
        "        \n",
        "        if self.skip:\n",
        "            \n",
        "            # Forward on FCN with Skip Connections.\n",
        "            fv_init = self.init(x)\n",
        "            fv1 = self.layer1(fv_init)\n",
        "            fv2 = self.layer2(fv1)\n",
        "            fv3 = self.layer3(fv2)\n",
        "            fv4 = self.layer4(fv3)\n",
        "            \n",
        "            fv_final = torch.cat([F.upsample(fv1, x.size()[2:], mode='bilinear'),\n",
        "                                  F.upsample(fv4, x.size()[2:], mode='bilinear')], 1)\n",
        "            \n",
        "        else:\n",
        "            \n",
        "            # Forward on FCN without Skip Connections.\n",
        "            fv_init = self.init(x)\n",
        "            fv1 = self.layer1(fv_init)\n",
        "            fv2 = self.layer2(fv1)\n",
        "            fv3 = self.layer3(fv2)\n",
        "            fv4 = self.layer4(fv3)\n",
        "            \n",
        "            fv_final = F.upsample(fv4, x.size()[2:], mode='bilinear')\n",
        "            \n",
        "        classif1 = self.classifier1(fv_final)\n",
        "        output = self.final(classif1)\n",
        "        \n",
        "        if feat:\n",
        "            return (output, classif1, F.upsample(fv2, x.size()[2:], mode='bilinear'))\n",
        "        else:\n",
        "            return output"
      ],
      "metadata": {
        "id": "qyayGbsc53Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCNDenseNet121(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_channels, num_classes, pretrained=True, skip=True, hidden_classes=None):\n",
        "\n",
        "        super(FCNDenseNet121, self).__init__()\n",
        "\n",
        "        self.skip = skip\n",
        "        \n",
        "        # DenseNet with Skip Connections (adapted from FCN-8s).\n",
        "        densenet = models.densenet121(pretrained=pretrained, progress=False)\n",
        "\n",
        "        if pretrained:\n",
        "            self.init = densenet.features[:4]\n",
        "        else:\n",
        "            self.init = nn.Sequential(\n",
        "                nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "            )\n",
        "        self.dense1 = densenet.features[4:6]\n",
        "        self.dense2 = densenet.features[6:8]\n",
        "        self.dense3 = densenet.features[8:10]\n",
        "        self.dense4 = densenet.features[10:12]\n",
        "        \n",
        "        if self.skip:\n",
        "            \n",
        "            if hidden_classes is None:\n",
        "                self.classifier1 = nn.Sequential(\n",
        "                    nn.Conv2d(1024 + 256, 64, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(64),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout2d(0.5),\n",
        "                )\n",
        "                self.final = nn.Conv2d(64, num_classes, kernel_size=3, padding=1)\n",
        "            else:\n",
        "                self.classifier1 = nn.Sequential(\n",
        "                    nn.Conv2d(1024 + 256, 64, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(64),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout2d(0.5),\n",
        "                )\n",
        "                self.final = nn.Conv2d(64, num_classes - len(hidden_classes), kernel_size=3, padding=1)\n",
        "                \n",
        "        else:\n",
        "\n",
        "            if hidden_classes is None:\n",
        "                self.classifier1 = nn.Sequential(\n",
        "                    nn.Conv2d(1024, 64, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(64),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout2d(0.5),\n",
        "                )\n",
        "                self.final = nn.Conv2d(64, num_classes, kernel_size=3, padding=1)\n",
        "            else:\n",
        "                self.classifier1 = nn.Sequential(\n",
        "                    nn.Conv2d(1024, 64, kernel_size=3, padding=1),\n",
        "                    nn.BatchNorm2d(64),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout2d(0.5),\n",
        "                )\n",
        "                self.final = nn.Conv2d(64, num_classes - len(hidden_classes), kernel_size=3, padding=1)\n",
        "        \n",
        "        if not pretrained:\n",
        "            initialize_weights(self)\n",
        "        else:\n",
        "            initialize_weights(self.classifier1)\n",
        "            initialize_weights(self.final)\n",
        "            \n",
        "\n",
        "    def forward(self, x, feat=False):\n",
        "        \n",
        "        if self.skip:\n",
        "            \n",
        "            # Forward on FCN with Skip Connections.\n",
        "            fv_init = self.init(x)\n",
        "            fv1 = self.dense1(fv_init)\n",
        "            fv2 = self.dense2(fv1)\n",
        "            fv3 = self.dense3(fv2)\n",
        "            fv4 = self.dense4(fv3)\n",
        "\n",
        "            fv_final = torch.cat([F.upsample(fv2, x.size()[2:], mode='bilinear'),\n",
        "                                  F.upsample(fv4, x.size()[2:], mode='bilinear')], 1)\n",
        "\n",
        "        else:\n",
        "\n",
        "            # Forward on FCN without Skip Connections.\n",
        "            fv_init = self.init(x)\n",
        "            fv1 = self.dense1(fv_init)\n",
        "            fv2 = self.dense2(fv1)\n",
        "            fv3 = self.dense3(fv2)\n",
        "            fv4 = self.dense4(fv3)\n",
        "\n",
        "            fv_final = F.upsample(fv4, x.size()[2:], mode='bilinear')\n",
        "\n",
        "        classif1 = self.classifier1(fv_final)\n",
        "        output = self.final(classif1)\n",
        "        \n",
        "        if feat:\n",
        "            return (output, classif1, F.upsample(fv2, x.size()[2:], mode='bilinear'))\n",
        "\n",
        "        else:\n",
        "            return output"
      ],
      "metadata": {
        "id": "hI_k2LFlplbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Misc"
      ],
      "metadata": {
        "id": "mzJJvRw_Xs7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import ceil\n",
        "\n",
        "def check_mkdir(dir_name):\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.mkdir(dir_name)\n",
        "\n",
        "\n",
        "def initialize_weights(*models):\n",
        "    for model in models:\n",
        "        for module in model.modules():\n",
        "#             if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.Linear):\n",
        "                nn.init.kaiming_normal_(module.weight)\n",
        "                if module.bias is not None:\n",
        "                    module.bias.data.zero_()\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                module.weight.data.fill_(1)\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "\n",
        "def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
        "    factor = (kernel_size + 1) // 2\n",
        "    if kernel_size % 2 == 1:\n",
        "        center = factor - 1\n",
        "    else:\n",
        "        center = factor - 0.5\n",
        "    og = np.ogrid[:kernel_size, :kernel_size]\n",
        "    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n",
        "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype=np.float64)\n",
        "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
        "    return torch.from_numpy(weight).float()\n",
        "\n"
      ],
      "metadata": {
        "id": "XoHHAhJqKU55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class unknownClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels):\n",
        "        super(unknownClassifier, self).__init__()\n",
        "        # output classes in, out\n",
        "        self.dimr = nn.Conv2d(in_channels, 2, kernel_size=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.dimr(x)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "6DVJdf673x7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossEntropyLoss2d(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True, ignore_index=-1):\n",
        "        super(CrossEntropyLoss2d, self).__init__()\n",
        "        self.nll_loss = nn.NLLLoss(weight, ignore_index=ignore_index, reduction='mean')\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "    \t#print(inputs.shape)\n",
        "        return self.nll_loss(F.log_softmax(inputs, dim = 1), targets)\n"
      ],
      "metadata": {
        "id": "vnCSIkTd19_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(*models):\n",
        "    for model in models:\n",
        "        for module in model.modules():\n",
        "#             if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.Linear):\n",
        "                nn.init.kaiming_normal_(module.weight)\n",
        "                if module.bias is not None:\n",
        "                    module.bias.data.zero_()\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                module.weight.data.fill_(1)\n",
        "                module.bias.data.zero_()\n"
      ],
      "metadata": {
        "id": "uBA38XvL6DAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train function"
      ],
      "metadata": {
        "id": "DPN36xn2Xm-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, net, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, hidden, args):\n",
        "\n",
        "    # Setting network for training mode.\n",
        "    net.train()\n",
        "\n",
        "    # Average Meter for batch loss.\n",
        "    train_loss = list()\n",
        "\n",
        "    # Iterating over batches.\n",
        "    for i, data in enumerate(train_loader):\n",
        "        \n",
        "        # Obtaining images, labels and paths for batch.\n",
        "        inps, labs, true, img_name = data\n",
        "        \n",
        "        # Casting tensors to cuda.\n",
        "        inps, labs, true = inps.to(DEVICE), labs.to(DEVICE), true.to(DEVICE)\n",
        "        \n",
        "        # Casting to cuda variables.\n",
        "        inps = Variable(inps).to(DEVICE)\n",
        "        labs = Variable(labs).to(DEVICE)\n",
        "        true = Variable(true).to(DEVICE)\n",
        "        \n",
        "        # Clears the gradients of optimizer.\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forwarding.\n",
        "        outs = net(inps)\n",
        "        soft_outs = F.softmax(outs, dim=1)\n",
        "        \n",
        "        # Obtaining predictions.\n",
        "        prds = soft_outs.data.max(1)[1]\n",
        "        \n",
        "        # Computing loss.\n",
        "        loss = criterion(outs, labs)\n",
        "        \n",
        "        # Computing backpropagation.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Appending images for epoch loss calculation.\n",
        "        # prds = prds.squeeze_(1).squeeze_(0).cpu().numpy()\n",
        "        \n",
        "        # inps_np = inps.detach().squeeze(0).cpu().numpy()\n",
        "        # labs_np = labs.detach().squeeze(0).cpu().numpy()\n",
        "        # true_np = true.detach().squeeze(0).cpu().numpy()\n",
        "        \n",
        "        # Updating loss meter.\n",
        "        train_loss.append(loss.data.item())\n",
        "        \n",
        "        # Printing.\n",
        "        if (i + 1) % print_freq == 0:\n",
        "            print('[epoch %d], [iter %d / %d], [train loss %.5f]' % (epoch, i + 1, len(train_loader), np.asarray(train_loss).mean()))\n",
        "            sys.stdout.flush()\n",
        "    \n",
        "    sys.stdout.flush()"
      ],
      "metadata": {
        "id": "Vwva9Uxe_jLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test function"
      ],
      "metadata": {
        "id": "I9CuiDEmXYZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_loader, net, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, hidden, args, save_images, save_model):\n",
        "    \n",
        "    # Setting network for evaluation mode.\n",
        "    net.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        # Creating output directory.\n",
        "        check_mkdir(os.path.join(outp_path, exp_name, 'epoch_' + str(epoch)))\n",
        "        \n",
        "        # Iterating over batches.\n",
        "        for i, data in enumerate(test_loader):\n",
        "            \n",
        "            print('Test Batch %d/%d' % (i + 1, len(test_loader)))\n",
        "            sys.stdout.flush()\n",
        "            \n",
        "            # Obtaining images, labels and paths for batch.\n",
        "            inps_batch, labs_batch, true_batch, img_name = data\n",
        "            \n",
        "            inps_batch = inps_batch.squeeze()\n",
        "            labs_batch = labs_batch.squeeze()\n",
        "            true_batch = true_batch.squeeze()\n",
        "            \n",
        "            # Iterating over patches inside batch.\n",
        "            for j in range(inps_batch.size(0)): #inps_batch.size(0)\n",
        "                \n",
        "                print('    Test MiniBatch %d/%d' % (j + 1, inps_batch.size(0)))\n",
        "                sys.stdout.flush()\n",
        "                \n",
        "                tic = time.time()\n",
        "                \n",
        "                for k in range(inps_batch.size(1)): #inps_batch.size(1)\n",
        "                    \n",
        "                    inps = inps_batch[j, k].unsqueeze(0)\n",
        "                    labs = labs_batch[j, k].unsqueeze(0)\n",
        "                    true = true_batch[j, k].unsqueeze(0)\n",
        "                    \n",
        "                    # Casting tensors to cuda.\n",
        "                    inps, labs, true = inps.to(DEVICE), labs.to(DEVICE), true.to(DEVICE)\n",
        "                    \n",
        "                    # Casting to cuda variables.\n",
        "                    inps = Variable(inps).to(DEVICE)\n",
        "                    labs = Variable(labs).to(DEVICE)\n",
        "                    true = Variable(true).to(DEVICE)\n",
        "                    \n",
        "                    # Forwarding.\n",
        "                    if conv_name == 'fcnwideresnet50':\n",
        "                        outs, classif1, fv2 = net(inps, feat=True)\n",
        "                    elif conv_name == 'fcndensenet121':\n",
        "                        outs, classif1, fv2 = net(inps, feat=True)\n",
        "                    \n",
        "                    # Computing probabilities.\n",
        "                    soft_outs = F.softmax(outs, dim=1)\n",
        "                    \n",
        "                    # Obtaining prior predictions.\n",
        "                    prds = soft_outs.data.max(1)[1]\n",
        "                    \n",
        "                    # Obtaining posterior predictions.\n",
        "                    # if conv_name == 'fcnwideresnet50':\n",
        "                    #     feat_flat = torch.cat([outs, classif1, fv2], 1)\n",
        "                    # elif conv_name == 'fcndensenet121':\n",
        "                    #     feat_flat = torch.cat([outs, classif1, fv2], 1)\n",
        "                        \n",
        "                    # feat_flat = feat_flat.permute(0, 2, 3, 1).contiguous().view(feat_flat.size(0) * feat_flat.size(2) * feat_flat.size(3), feat_flat.size(1)).cpu().numpy()\n",
        "                    # prds_flat = prds.cpu().numpy().ravel()\n",
        "                    # true_flat = true.cpu().numpy().ravel()\n",
        "                    \n",
        "                    # # Appending images for epoch loss calculation.\n",
        "                    inps_np = inps.detach().squeeze(0).cpu().numpy()\n",
        "                    labs_np = labs.detach().squeeze(0).cpu().numpy()\n",
        "                    true_np = true.detach().squeeze(0).cpu().numpy()\n",
        "                    \n",
        "                    # Saving predictions.\n",
        "                    if (save_images):\n",
        "                        \n",
        "                        # imag_path = os.path.join(outp_path, exp_name, 'epoch_' + str(epoch), img_name[0].replace('.tif', '_img_' + str(j) + '_' + str(k) + '.png'))\n",
        "                        # mask_path = os.path.join(outp_path, exp_name, 'epoch_' + str(epoch), img_name[0].replace('.tif', '_msk_' + str(j) + '_' + str(k) + '.png'))\n",
        "                        # true_path = os.path.join(outp_path, exp_name, 'epoch_' + str(epoch), img_name[0].replace('.tif', '_tru_' + str(j) + '_' + str(k) + '.png'))\n",
        "                        pred_path = os.path.join(outp_path, exp_name, 'epoch_' + str(epoch), img_name[0].replace('.tif', '_prd_' + str(j) + '_' + str(k) + '.png'))\n",
        "                        \n",
        "                        plt.figure(figsize=(16, 6))\n",
        "                        plt.subplot(141)\n",
        "                        plt.title(\"Image\")\n",
        "                        plt.imshow(np.transpose((inps_np[0:3,:,:] + 0.5), (1, 2, 0)))\n",
        "                        plt.subplot(142)\n",
        "                        plt.title(\"Mask\")\n",
        "                        plt.imshow(labs_np, cmap=lab_cmap_1)\n",
        "                        plt.clim(0, 5)\n",
        "                        plt.subplot(143)\n",
        "                        plt.title(\"True Mask\")\n",
        "                        plt.imshow(true_np, cmap=lab_cmap)\n",
        "                        plt.clim(0, 5)\n",
        "                        plt.subplot(144)\n",
        "                        plt.title(\"Prediction\")\n",
        "                        plt.imshow(prds.cpu().squeeze().numpy(), cmap=lab_cmap_1)\n",
        "                        plt.clim(0, 5)\n",
        "                        plt.savefig(pred_path)\n",
        "                        plt.clf()\n",
        "                        plt.close()\n",
        "                        # io.imsave(imag_path, np.transpose(((inps_np[0:3,:,:] + 0.5)*255).astype(np.uint8), (1, 2, 0)))\n",
        "                        # io.imsave(mask_path, util.img_as_ubyte(labs_np.astype(np.uint8)))\n",
        "                        # io.imsave(true_path, util.img_as_ubyte(true_np.astype(np.uint8)))\n",
        "                        # io.imsave(pred_path, util.img_as_ubyte(prds.cpu().squeeze().numpy().astype(np.uint8)))\n",
        "\n",
        "                toc = time.time()\n",
        "                print('        Elapsed Time: %.2f' % (toc - tic))\n",
        "        \n",
        "        sys.stdout.flush()\n",
        "        \n",
        "        if save_model:\n",
        "            \n",
        "            torch.save(net.state_dict(), os.path.join(ckpt_path, exp_name, 'model_' + str(epoch) + '.pth'))\n",
        "            torch.save(optimizer.state_dict(), os.path.join(ckpt_path, exp_name, 'opt_' + str(epoch) + '.pth'))"
      ],
      "metadata": {
        "id": "gwW16u5V_j11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functioning"
      ],
      "metadata": {
        "id": "S28YZi6IXdvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# potsdam\n",
        "lr = 1e-3\n",
        "weight_decay = 5e-6\n",
        "momentum = 0.9\n",
        "batch_size = 1\n",
        "# num_workers = 8\n",
        "print_freq = 1\n",
        "w_size = 224\n",
        "h_size = 224\n",
        "input_channels = 4\n",
        "num_classes = 6\n",
        "epoch_num = 600\n",
        "test_freq = 600\n",
        "save_freq = 600\n",
        "num_workers = 1\n",
        "conv_name = 'fcndensenet121'\n",
        "args = f'lr:{lr}, weight_decay:{weight_decay} momentum:{momentum} batch_size:{batch_size} num_workers:{num_workers} print_freq:{print_freq} \\\n",
        "        w_size:{w_size} h_size:{h_size} input_channels:{input_channels} num_classes:{num_classes} epoch_num:{epoch_num} test_freq:{test_freq} \\\n",
        "        save_freq:{save_freq} conv_name:{conv_name}'"
      ],
      "metadata": {
        "id": "egcNhdsyvKEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HiddenClasses = [1]\n",
        "num_known_classes = num_classes - len(HiddenClasses)\n",
        "num_unknown_classes = len(HiddenClasses)\n",
        "weights = [1.0 for i in range(num_known_classes)]\n",
        "weights = torch.FloatTensor(weights)\n",
        "DEVICE = 'cuda'"
      ],
      "metadata": {
        "id": "AUEHZZ9zemZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hidden class Nil\n",
        "traindata = ListDataset(potsdam, 'Potsdam', 'Train', (h_size, w_size), hidden_classes=HiddenClasses, overlap=False, use_dsm=True)\n",
        "trainloader = DataLoader(traindata, batch_size=None, num_workers=num_workers, shuffle=True)\n",
        "\n",
        "valdata = ListDataset(potsdam, 'Potsdam', 'Val', (h_size, w_size), hidden_classes=HiddenClasses, overlap=True, use_dsm=True)\n",
        "valloader = DataLoader(valdata, batch_size=1, num_workers=0, shuffle=True)\n",
        "\n",
        "testdata = ListDataset(potsdam, 'Potsdam', 'Test', (h_size, w_size), hidden_classes=HiddenClasses, overlap=True, use_dsm=True)\n",
        "testloader = DataLoader(testdata, batch_size=1, num_workers=0, shuffle=True)"
      ],
      "metadata": {
        "id": "TzZDv-uckcfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(msk):\n",
        "    msk = msk.astype(np.int64)\n",
        "    new = np.zeros((msk.shape[0], msk.shape[1]), dtype=np.int64)\n",
        "    \n",
        "    msk = msk // 255\n",
        "    msk = msk * (1, 7, 49)\n",
        "    msk = msk.sum(axis=2)\n",
        "\n",
        "    new[msk == 1 + 7 + 49] = 0 # Street.\n",
        "    new[msk ==         49] = 1 # Building.\n",
        "    new[msk ==     7 + 4.max(1)[1]9] = 2 # Grass.\n",
        "    new[msk ==     7     ] = 3 # Tree.\n",
        "    new[msk == 1 + 7     ] = 4 # Car.\n",
        "    new[msk == 1         ] = 5 # Surfaces.\n",
        "    new[msk == 0         ] = 6 # Boundaries.\n",
        "\n",
        "    return new"
      ],
      "metadata": {
        "id": "P9p2Ah6ijhq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import colors\n",
        "'''\n",
        "Vaihingen/Potsdam classes:\n",
        "    0 = Street\n",
        "    1 = Building\n",
        "    2 = Grass\n",
        "    3 = Tree\n",
        "    4 = Car\n",
        "    5 = Surfaces\n",
        "    6 = Boundaries\n",
        "'''\n",
        "# no hidden class cmap\n",
        "cmap_list = [\n",
        "    (1.0, 1.0, 1.0, 1.0), # street. \n",
        "    (0.0, 0.0, 1.0, 1.0), # Building\n",
        "    (0.0, 1.0, 1.0, 1.0), # Grass.\n",
        "    (0.0, 1.0, 0.0, 1.0), # Tree.\n",
        "    (1.0, 1.0, 0.0, 1.0), # Car.\n",
        "    (1.0, 0.0, 0.0, 1.0),  # surfaces\n",
        "    # (0.0, 0.0, 0.0, 1.0), # Boundaries (if present).\n",
        "]\n",
        "lab_cmap = colors.ListedColormap(cmap_list)"
      ],
      "metadata": {
        "id": "LsRoM5SkGyvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmap_list_1 = [\n",
        "    (1.0, 1.0, 1.0, 1.0), # street.\n",
        "    (0.0, 1.0, 1.0, 1.0), # Grass.\n",
        "    (0.0, 1.0, 0.0, 1.0), # Tree.\n",
        "    (1.0, 1.0, 0.0, 1.0), # Car.\n",
        "    (1.0, 0.0, 0.0, 1.0),  # surfaces       \n",
        "    (0.0, 0.0, 1.0, 1.0), # Building  \n",
        "    # (0.0, 0.0, 0.0, 1.0), # Boundaries (if present).\n",
        "]\n",
        "lab_cmap_1 = colors.ListedColormap(cmap_list_1)"
      ],
      "metadata": {
        "id": "mYaD5QMosrqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, msk, msk_true, spl = valdata[0]\n",
        "a = 0\n",
        "b = 29#np.random.randint(30)\n",
        "plt.subplot(131)\n",
        "plt.title(\"Image\")\n",
        "plt.imshow(img[a, b, :3, :, :].permute(1, 2, 0)+0.5)\n",
        "plt.subplot(132)\n",
        "plt.title(\"Mask\")\n",
        "plt.imshow(msk[a, b, :, :], cmap=lab_cmap_1)\n",
        "plt.clim(0, 5)\n",
        "plt.subplot(133)\n",
        "plt.title(\"True Mask\")\n",
        "plt.imshow(msk_true[a, b, :, :], cmap=lab_cmap)\n",
        "plt.clim(0, 5)\n",
        "# plt.subplot(144)\n",
        "# plt.title(\"Prediction\")\n",
        "# plt.imshow(prds.cpu().squeeze().numpy(), cmap=lab_cmap_1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "bgKcrVtsy2MD",
        "outputId": "cfff0d30-500f-43b1-d1dd-57ed8b27cbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(msk[a, b, 200, 50], msk_true[a, b, 200, 50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXAQnuRAUYUU",
        "outputId": "1ccf8abd-afbe-4862-a52d-1f217770e7e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6) tensor(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outp_path = '/content/drive/MyDrive/BTPII/outputs'\n",
        "ckpt_path = '/content/drive/MyDrive/BTPII/checkpoints'\n",
        "exp_name = 'hc_0_exp2'\n",
        "best_record = {'epoch': 0, 'lr': 1e-4, 'val_loss': 1e10, 'acc': 0, 'acc_cls': 0, 'iou': 0}"
      ],
      "metadata": {
        "id": "k_BHks--cXSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnhkKG3YXJcC",
        "outputId": "4ab5e82f-064e-4b0f-a775-254336d18d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = FCNWideResNet50(input_channels, num_classes, pretrained=False, skip=True, hidden_classes=HiddenClasses).to(DEVICE)\n",
        "model = FCNDenseNet121(input_channels, num_classes, pretrained=False, skip=True, hidden_classes=HiddenClasses).to(DEVICE)\n",
        "criterion = CrossEntropyLoss2d(weight=weights, size_average=False, ignore_index=num_classes).to(DEVICE)\n",
        "# criterion = nn.CrossEntropyLoss(weight=weights, size_average=False, ignore_index=num_classes).to(DEVICE)\n",
        "optimizer = torch.optim.Adam([param for name, param in model.named_parameters() if name[-4:] == 'bias'], lr=lr, weight_decay=weight_decay, betas=(momentum, 0.99))\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, epoch_num//3, 0.2)\n",
        "\n",
        "check_mkdir(ckpt_path)\n",
        "check_mkdir(os.path.join(ckpt_path, exp_name))\n",
        "check_mkdir(outp_path)\n",
        "check_mkdir(os.path.join(outp_path, exp_name))"
      ],
      "metadata": {
        "id": "IbwXdu6KQSln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_state_dict(torch.load(os.path.join(ckpt_path, exp_name, 'model_33.pth')))\n",
        "# model.load_state_dict(torch.load(os.path.join(potsdam, 'model_600.pth')))\n",
        "# model.eval()"
      ],
      "metadata": {
        "id": "XxZu3cD2VYSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime"
      ],
      "metadata": {
        "id": "R_LtonxnU4lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.backends import cudnn\n",
        "cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "Jj2uvn9h0969"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_epoch = 1\n",
        "open(os.path.join(ckpt_path, exp_name, str(datetime.datetime.now()) + '.txt'), 'w').write(args + '\\n\\n')\n",
        "\n",
        "for epoch in range(curr_epoch, epoch_num + 1):\n",
        "\n",
        "    # Training function.\n",
        "    train(trainloader, model, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, HiddenClasses, {})\n",
        "\n",
        "    if epoch % test_freq == 0:\n",
        "            \n",
        "        torch.save(model.state_dict(), os.path.join(ckpt_path, exp_name, 'model_' + str(epoch) + '.pth'))\n",
        "        torch.save(optimizer.state_dict(), os.path.join(ckpt_path, exp_name, 'opt_' + str(epoch) + '.pth'))\n",
        "            \n",
        "            # Computing test.\n",
        "        test(valloader, model, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, HiddenClasses, {}, True, True) #epoch % args['save_freq'] == 0)\n",
        "        \n",
        "    scheduler.step()        \n",
        "    print('Exiting...')"
      ],
      "metadata": {
        "id": "Tu_DHtK0Kvmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce87110-6406-4eca-c974-77a6365f20f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 1], [iter 1 / 25], [train loss 2.38477]\n",
            "[epoch 1], [iter 2 / 25], [train loss 2.04557]\n",
            "[epoch 1], [iter 3 / 25], [train loss 1.87757]\n",
            "[epoch 1], [iter 4 / 25], [train loss 1.95570]\n",
            "[epoch 1], [iter 5 / 25], [train loss 1.98510]\n",
            "[epoch 1], [iter 6 / 25], [train loss 1.92288]\n",
            "[epoch 1], [iter 7 / 25], [train loss 1.93058]\n",
            "[epoch 1], [iter 8 / 25], [train loss 2.03451]\n",
            "[epoch 1], [iter 9 / 25], [train loss 2.06970]\n",
            "[epoch 1], [iter 10 / 25], [train loss 2.08117]\n",
            "[epoch 1], [iter 11 / 25], [train loss 2.08806]\n",
            "[epoch 1], [iter 12 / 25], [train loss 2.05087]\n",
            "[epoch 1], [iter 13 / 25], [train loss 2.04209]\n",
            "[epoch 1], [iter 14 / 25], [train loss 2.03332]\n",
            "[epoch 1], [iter 15 / 25], [train loss 2.01781]\n",
            "[epoch 1], [iter 16 / 25], [train loss 2.02682]\n",
            "[epoch 1], [iter 17 / 25], [train loss 2.04809]\n",
            "[epoch 1], [iter 18 / 25], [train loss 2.05321]\n",
            "[epoch 1], [iter 19 / 25], [train loss 2.08267]\n",
            "[epoch 1], [iter 20 / 25], [train loss 2.08603]\n",
            "[epoch 1], [iter 21 / 25], [train loss 2.08550]\n",
            "[epoch 1], [iter 22 / 25], [train loss 2.07131]\n",
            "[epoch 1], [iter 23 / 25], [train loss 2.07385]\n",
            "[epoch 1], [iter 24 / 25], [train loss 2.06908]\n",
            "[epoch 1], [iter 25 / 25], [train loss 2.06239]\n",
            "Exiting...\n",
            "[epoch 2], [iter 1 / 25], [train loss 1.98367]\n",
            "[epoch 2], [iter 2 / 25], [train loss 1.84475]\n",
            "[epoch 2], [iter 3 / 25], [train loss 1.90683]\n",
            "[epoch 2], [iter 4 / 25], [train loss 1.81129]\n",
            "[epoch 2], [iter 5 / 25], [train loss 1.84210]\n",
            "[epoch 2], [iter 6 / 25], [train loss 1.87633]\n",
            "[epoch 2], [iter 7 / 25], [train loss 1.86799]\n",
            "[epoch 2], [iter 8 / 25], [train loss 1.76859]\n",
            "[epoch 2], [iter 9 / 25], [train loss 1.74713]\n",
            "[epoch 2], [iter 10 / 25], [train loss 1.80032]\n",
            "[epoch 2], [iter 11 / 25], [train loss 1.81249]\n",
            "[epoch 2], [iter 12 / 25], [train loss 1.83485]\n",
            "[epoch 2], [iter 13 / 25], [train loss 1.83331]\n",
            "[epoch 2], [iter 14 / 25], [train loss 1.85241]\n",
            "[epoch 2], [iter 15 / 25], [train loss 1.86458]\n",
            "[epoch 2], [iter 16 / 25], [train loss 1.86036]\n",
            "[epoch 2], [iter 17 / 25], [train loss 1.87260]\n",
            "[epoch 2], [iter 18 / 25], [train loss 1.89189]\n",
            "[epoch 2], [iter 19 / 25], [train loss 1.89170]\n",
            "[epoch 2], [iter 20 / 25], [train loss 1.89562]\n",
            "[epoch 2], [iter 21 / 25], [train loss 1.88454]\n",
            "[epoch 2], [iter 22 / 25], [train loss 1.90255]\n",
            "[epoch 2], [iter 23 / 25], [train loss 1.91458]\n",
            "[epoch 2], [iter 24 / 25], [train loss 1.93530]\n",
            "[epoch 2], [iter 25 / 25], [train loss 1.91710]\n",
            "Exiting...\n",
            "[epoch 3], [iter 1 / 25], [train loss 1.36457]\n",
            "[epoch 3], [iter 2 / 25], [train loss 1.69347]\n",
            "[epoch 3], [iter 3 / 25], [train loss 1.83189]\n",
            "[epoch 3], [iter 4 / 25], [train loss 1.79515]\n",
            "[epoch 3], [iter 5 / 25], [train loss 1.77190]\n",
            "[epoch 3], [iter 6 / 25], [train loss 1.80976]\n",
            "[epoch 3], [iter 7 / 25], [train loss 1.86806]\n",
            "[epoch 3], [iter 8 / 25], [train loss 1.84819]\n",
            "[epoch 3], [iter 9 / 25], [train loss 1.90441]\n",
            "[epoch 3], [iter 10 / 25], [train loss 1.92269]\n",
            "[epoch 3], [iter 11 / 25], [train loss 1.98478]\n",
            "[epoch 3], [iter 12 / 25], [train loss 1.95633]\n",
            "[epoch 3], [iter 13 / 25], [train loss 1.92638]\n",
            "[epoch 3], [iter 14 / 25], [train loss 1.92820]\n",
            "[epoch 3], [iter 15 / 25], [train loss 1.89610]\n",
            "[epoch 3], [iter 16 / 25], [train loss 1.89525]\n",
            "[epoch 3], [iter 17 / 25], [train loss 1.92184]\n",
            "[epoch 3], [iter 18 / 25], [train loss 1.93479]\n",
            "[epoch 3], [iter 19 / 25], [train loss 1.92978]\n",
            "[epoch 3], [iter 20 / 25], [train loss 1.92288]\n",
            "[epoch 3], [iter 21 / 25], [train loss 1.93111]\n",
            "[epoch 3], [iter 22 / 25], [train loss 1.93914]\n",
            "[epoch 3], [iter 23 / 25], [train loss 1.92425]\n",
            "[epoch 3], [iter 24 / 25], [train loss 1.91830]\n",
            "[epoch 3], [iter 25 / 25], [train loss 1.89970]\n",
            "Exiting...\n",
            "[epoch 4], [iter 1 / 25], [train loss 1.73325]\n",
            "[epoch 4], [iter 2 / 25], [train loss 1.64933]\n",
            "[epoch 4], [iter 3 / 25], [train loss 1.69347]\n",
            "[epoch 4], [iter 4 / 25], [train loss 1.70644]\n",
            "[epoch 4], [iter 5 / 25], [train loss 1.71605]\n",
            "[epoch 4], [iter 6 / 25], [train loss 1.69699]\n",
            "[epoch 4], [iter 7 / 25], [train loss 1.77214]\n",
            "[epoch 4], [iter 8 / 25], [train loss 1.76871]\n",
            "[epoch 4], [iter 9 / 25], [train loss 1.81623]\n",
            "[epoch 4], [iter 10 / 25], [train loss 1.84102]\n",
            "[epoch 4], [iter 11 / 25], [train loss 1.86457]\n",
            "[epoch 4], [iter 12 / 25], [train loss 1.82566]\n",
            "[epoch 4], [iter 13 / 25], [train loss 1.83888]\n",
            "[epoch 4], [iter 14 / 25], [train loss 1.87246]\n",
            "[epoch 4], [iter 15 / 25], [train loss 1.88924]\n",
            "[epoch 4], [iter 16 / 25], [train loss 1.86088]\n",
            "[epoch 4], [iter 17 / 25], [train loss 1.85629]\n",
            "[epoch 4], [iter 18 / 25], [train loss 1.84626]\n",
            "[epoch 4], [iter 19 / 25], [train loss 1.83874]\n",
            "[epoch 4], [iter 20 / 25], [train loss 1.85840]\n",
            "[epoch 4], [iter 21 / 25], [train loss 1.84615]\n",
            "[epoch 4], [iter 22 / 25], [train loss 1.84775]\n",
            "[epoch 4], [iter 23 / 25], [train loss 1.87655]\n",
            "[epoch 4], [iter 24 / 25], [train loss 1.87008]\n",
            "[epoch 4], [iter 25 / 25], [train loss 1.86027]\n",
            "Exiting...\n",
            "[epoch 5], [iter 1 / 25], [train loss 1.78252]\n",
            "[epoch 5], [iter 2 / 25], [train loss 1.71586]\n",
            "[epoch 5], [iter 3 / 25], [train loss 1.85571]\n",
            "[epoch 5], [iter 4 / 25], [train loss 1.72800]\n",
            "[epoch 5], [iter 5 / 25], [train loss 1.77307]\n",
            "[epoch 5], [iter 6 / 25], [train loss 1.72013]\n",
            "[epoch 5], [iter 7 / 25], [train loss 1.65933]\n",
            "[epoch 5], [iter 8 / 25], [train loss 1.67775]\n",
            "[epoch 5], [iter 9 / 25], [train loss 1.77796]\n",
            "[epoch 5], [iter 10 / 25], [train loss 1.84973]\n",
            "[epoch 5], [iter 11 / 25], [train loss 1.84464]\n",
            "[epoch 5], [iter 12 / 25], [train loss 1.78480]\n",
            "[epoch 5], [iter 13 / 25], [train loss 1.81653]\n",
            "[epoch 5], [iter 14 / 25], [train loss 1.80571]\n",
            "[epoch 5], [iter 15 / 25], [train loss 1.79628]\n",
            "[epoch 5], [iter 16 / 25], [train loss 1.78871]\n",
            "[epoch 5], [iter 17 / 25], [train loss 1.76773]\n",
            "[epoch 5], [iter 18 / 25], [train loss 1.78231]\n",
            "[epoch 5], [iter 19 / 25], [train loss 1.76451]\n",
            "[epoch 5], [iter 20 / 25], [train loss 1.76210]\n",
            "[epoch 5], [iter 21 / 25], [train loss 1.77435]\n",
            "[epoch 5], [iter 22 / 25], [train loss 1.75085]\n",
            "[epoch 5], [iter 23 / 25], [train loss 1.76503]\n",
            "[epoch 5], [iter 24 / 25], [train loss 1.75063]\n",
            "[epoch 5], [iter 25 / 25], [train loss 1.76930]\n",
            "Exiting...\n",
            "[epoch 6], [iter 1 / 25], [train loss 2.31495]\n",
            "[epoch 6], [iter 2 / 25], [train loss 2.11309]\n",
            "[epoch 6], [iter 3 / 25], [train loss 1.78887]\n",
            "[epoch 6], [iter 4 / 25], [train loss 1.77279]\n",
            "[epoch 6], [iter 5 / 25], [train loss 1.78416]\n",
            "[epoch 6], [iter 6 / 25], [train loss 1.78080]\n",
            "[epoch 6], [iter 7 / 25], [train loss 1.78788]\n",
            "[epoch 6], [iter 8 / 25], [train loss 1.76153]\n",
            "[epoch 6], [iter 9 / 25], [train loss 1.76850]\n",
            "[epoch 6], [iter 10 / 25], [train loss 1.81559]\n",
            "[epoch 6], [iter 11 / 25], [train loss 1.80454]\n",
            "[epoch 6], [iter 12 / 25], [train loss 1.79832]\n",
            "[epoch 6], [iter 13 / 25], [train loss 1.78681]\n",
            "[epoch 6], [iter 14 / 25], [train loss 1.79781]\n",
            "[epoch 6], [iter 15 / 25], [train loss 1.77045]\n",
            "[epoch 6], [iter 16 / 25], [train loss 1.74152]\n",
            "[epoch 6], [iter 17 / 25], [train loss 1.75258]\n",
            "[epoch 6], [iter 18 / 25], [train loss 1.72707]\n",
            "[epoch 6], [iter 19 / 25], [train loss 1.71157]\n",
            "[epoch 6], [iter 20 / 25], [train loss 1.71217]\n",
            "[epoch 6], [iter 21 / 25], [train loss 1.75007]\n",
            "[epoch 6], [iter 22 / 25], [train loss 1.75649]\n",
            "[epoch 6], [iter 23 / 25], [train loss 1.76414]\n",
            "[epoch 6], [iter 24 / 25], [train loss 1.75069]\n",
            "[epoch 6], [iter 25 / 25], [train loss 1.76680]\n",
            "Exiting...\n",
            "[epoch 7], [iter 1 / 25], [train loss 1.47326]\n",
            "[epoch 7], [iter 2 / 25], [train loss 1.69353]\n",
            "[epoch 7], [iter 3 / 25], [train loss 1.88177]\n",
            "[epoch 7], [iter 4 / 25], [train loss 1.82512]\n",
            "[epoch 7], [iter 5 / 25], [train loss 1.75604]\n",
            "[epoch 7], [iter 6 / 25], [train loss 1.73581]\n",
            "[epoch 7], [iter 7 / 25], [train loss 1.81750]\n",
            "[epoch 7], [iter 8 / 25], [train loss 1.81664]\n",
            "[epoch 7], [iter 9 / 25], [train loss 1.82925]\n",
            "[epoch 7], [iter 10 / 25], [train loss 1.76777]\n",
            "[epoch 7], [iter 11 / 25], [train loss 1.80952]\n",
            "[epoch 7], [iter 12 / 25], [train loss 1.77638]\n",
            "[epoch 7], [iter 13 / 25], [train loss 1.71851]\n",
            "[epoch 7], [iter 14 / 25], [train loss 1.74123]\n",
            "[epoch 7], [iter 15 / 25], [train loss 1.79292]\n",
            "[epoch 7], [iter 16 / 25], [train loss 1.79871]\n",
            "[epoch 7], [iter 17 / 25], [train loss 1.78014]\n",
            "[epoch 7], [iter 18 / 25], [train loss 1.76801]\n",
            "[epoch 7], [iter 19 / 25], [train loss 1.75730]\n",
            "[epoch 7], [iter 20 / 25], [train loss 1.73802]\n",
            "[epoch 7], [iter 21 / 25], [train loss 1.75060]\n",
            "[epoch 7], [iter 22 / 25], [train loss 1.75619]\n",
            "[epoch 7], [iter 23 / 25], [train loss 1.74274]\n",
            "[epoch 7], [iter 24 / 25], [train loss 1.74017]\n",
            "[epoch 7], [iter 25 / 25], [train loss 1.73907]\n",
            "Exiting...\n",
            "[epoch 8], [iter 1 / 25], [train loss 1.31070]\n",
            "[epoch 8], [iter 2 / 25], [train loss 1.41426]\n",
            "[epoch 8], [iter 3 / 25], [train loss 1.55700]\n",
            "[epoch 8], [iter 4 / 25], [train loss 1.51407]\n",
            "[epoch 8], [iter 5 / 25], [train loss 1.48436]\n",
            "[epoch 8], [iter 6 / 25], [train loss 1.46815]\n",
            "[epoch 8], [iter 7 / 25], [train loss 1.52785]\n",
            "[epoch 8], [iter 8 / 25], [train loss 1.53392]\n",
            "[epoch 8], [iter 9 / 25], [train loss 1.49455]\n",
            "[epoch 8], [iter 10 / 25], [train loss 1.46863]\n",
            "[epoch 8], [iter 11 / 25], [train loss 1.49084]\n",
            "[epoch 8], [iter 12 / 25], [train loss 1.54223]\n",
            "[epoch 8], [iter 13 / 25], [train loss 1.53103]\n",
            "[epoch 8], [iter 14 / 25], [train loss 1.50248]\n",
            "[epoch 8], [iter 15 / 25], [train loss 1.52886]\n",
            "[epoch 8], [iter 16 / 25], [train loss 1.52221]\n",
            "[epoch 8], [iter 17 / 25], [train loss 1.51332]\n",
            "[epoch 8], [iter 18 / 25], [train loss 1.53635]\n",
            "[epoch 8], [iter 19 / 25], [train loss 1.53426]\n",
            "[epoch 8], [iter 20 / 25], [train loss 1.56791]\n",
            "[epoch 8], [iter 21 / 25], [train loss 1.58214]\n",
            "[epoch 8], [iter 22 / 25], [train loss 1.57173]\n",
            "[epoch 8], [iter 23 / 25], [train loss 1.57709]\n",
            "[epoch 8], [iter 24 / 25], [train loss 1.57510]\n",
            "[epoch 8], [iter 25 / 25], [train loss 1.57955]\n",
            "Exiting...\n",
            "[epoch 9], [iter 1 / 25], [train loss 1.95495]\n",
            "[epoch 9], [iter 2 / 25], [train loss 1.68368]\n",
            "[epoch 9], [iter 3 / 25], [train loss 1.77468]\n",
            "[epoch 9], [iter 4 / 25], [train loss 1.59523]\n",
            "[epoch 9], [iter 5 / 25], [train loss 1.59542]\n",
            "[epoch 9], [iter 6 / 25], [train loss 1.56380]\n",
            "[epoch 9], [iter 7 / 25], [train loss 1.55903]\n",
            "[epoch 9], [iter 8 / 25], [train loss 1.56368]\n",
            "[epoch 9], [iter 9 / 25], [train loss 1.55120]\n",
            "[epoch 9], [iter 10 / 25], [train loss 1.56574]\n",
            "[epoch 9], [iter 11 / 25], [train loss 1.57515]\n",
            "[epoch 9], [iter 12 / 25], [train loss 1.59142]\n",
            "[epoch 9], [iter 13 / 25], [train loss 1.60331]\n",
            "[epoch 9], [iter 14 / 25], [train loss 1.60926]\n",
            "[epoch 9], [iter 15 / 25], [train loss 1.64793]\n",
            "[epoch 9], [iter 16 / 25], [train loss 1.71353]\n",
            "[epoch 9], [iter 17 / 25], [train loss 1.67484]\n",
            "[epoch 9], [iter 18 / 25], [train loss 1.65217]\n",
            "[epoch 9], [iter 19 / 25], [train loss 1.64055]\n",
            "[epoch 9], [iter 20 / 25], [train loss 1.63588]\n",
            "[epoch 9], [iter 21 / 25], [train loss 1.62435]\n",
            "[epoch 9], [iter 22 / 25], [train loss 1.65541]\n",
            "[epoch 9], [iter 23 / 25], [train loss 1.65845]\n",
            "[epoch 9], [iter 24 / 25], [train loss 1.66553]\n",
            "[epoch 9], [iter 25 / 25], [train loss 1.66521]\n",
            "Exiting...\n",
            "[epoch 10], [iter 1 / 25], [train loss 1.53830]\n",
            "[epoch 10], [iter 2 / 25], [train loss 1.68458]\n",
            "[epoch 10], [iter 3 / 25], [train loss 1.77751]\n",
            "[epoch 10], [iter 4 / 25], [train loss 1.73584]\n",
            "[epoch 10], [iter 5 / 25], [train loss 1.63933]\n",
            "[epoch 10], [iter 6 / 25], [train loss 1.58173]\n",
            "[epoch 10], [iter 7 / 25], [train loss 1.58859]\n",
            "[epoch 10], [iter 8 / 25], [train loss 1.58399]\n",
            "[epoch 10], [iter 9 / 25], [train loss 1.56049]\n",
            "[epoch 10], [iter 10 / 25], [train loss 1.52953]\n",
            "[epoch 10], [iter 11 / 25], [train loss 1.50840]\n",
            "[epoch 10], [iter 12 / 25], [train loss 1.52275]\n",
            "[epoch 10], [iter 13 / 25], [train loss 1.52403]\n",
            "[epoch 10], [iter 14 / 25], [train loss 1.53224]\n",
            "[epoch 10], [iter 15 / 25], [train loss 1.51615]\n",
            "[epoch 10], [iter 16 / 25], [train loss 1.51332]\n",
            "[epoch 10], [iter 17 / 25], [train loss 1.51472]\n",
            "[epoch 10], [iter 18 / 25], [train loss 1.53044]\n",
            "[epoch 10], [iter 19 / 25], [train loss 1.53355]\n",
            "[epoch 10], [iter 20 / 25], [train loss 1.54565]\n",
            "[epoch 10], [iter 21 / 25], [train loss 1.53876]\n",
            "[epoch 10], [iter 22 / 25], [train loss 1.53980]\n",
            "[epoch 10], [iter 23 / 25], [train loss 1.56522]\n",
            "[epoch 10], [iter 24 / 25], [train loss 1.59425]\n",
            "[epoch 10], [iter 25 / 25], [train loss 1.57866]\n",
            "Exiting...\n",
            "[epoch 11], [iter 1 / 25], [train loss 1.95318]\n",
            "[epoch 11], [iter 2 / 25], [train loss 1.81654]\n",
            "[epoch 11], [iter 3 / 25], [train loss 1.56340]\n",
            "[epoch 11], [iter 4 / 25], [train loss 1.49194]\n",
            "[epoch 11], [iter 5 / 25], [train loss 1.43942]\n",
            "[epoch 11], [iter 6 / 25], [train loss 1.51995]\n",
            "[epoch 11], [iter 7 / 25], [train loss 1.56468]\n",
            "[epoch 11], [iter 8 / 25], [train loss 1.56755]\n",
            "[epoch 11], [iter 9 / 25], [train loss 1.61917]\n",
            "[epoch 11], [iter 10 / 25], [train loss 1.56886]\n",
            "[epoch 11], [iter 11 / 25], [train loss 1.61789]\n",
            "[epoch 11], [iter 12 / 25], [train loss 1.59176]\n",
            "[epoch 11], [iter 13 / 25], [train loss 1.57681]\n",
            "[epoch 11], [iter 14 / 25], [train loss 1.58508]\n",
            "[epoch 11], [iter 15 / 25], [train loss 1.59227]\n",
            "[epoch 11], [iter 16 / 25], [train loss 1.59468]\n",
            "[epoch 11], [iter 17 / 25], [train loss 1.55440]\n",
            "[epoch 11], [iter 18 / 25], [train loss 1.56213]\n",
            "[epoch 11], [iter 19 / 25], [train loss 1.54987]\n",
            "[epoch 11], [iter 20 / 25], [train loss 1.55452]\n",
            "[epoch 11], [iter 21 / 25], [train loss 1.56435]\n",
            "[epoch 11], [iter 22 / 25], [train loss 1.57792]\n",
            "[epoch 11], [iter 23 / 25], [train loss 1.57644]\n",
            "[epoch 11], [iter 24 / 25], [train loss 1.58467]\n",
            "[epoch 11], [iter 25 / 25], [train loss 1.57953]\n",
            "Exiting...\n",
            "[epoch 12], [iter 1 / 25], [train loss 2.12926]\n",
            "[epoch 12], [iter 2 / 25], [train loss 1.80994]\n",
            "[epoch 12], [iter 3 / 25], [train loss 1.67147]\n",
            "[epoch 12], [iter 4 / 25], [train loss 1.66781]\n",
            "[epoch 12], [iter 5 / 25], [train loss 1.68003]\n",
            "[epoch 12], [iter 6 / 25], [train loss 1.72133]\n",
            "[epoch 12], [iter 7 / 25], [train loss 1.66523]\n",
            "[epoch 12], [iter 8 / 25], [train loss 1.63671]\n",
            "[epoch 12], [iter 9 / 25], [train loss 1.64359]\n",
            "[epoch 12], [iter 10 / 25], [train loss 1.65884]\n",
            "[epoch 12], [iter 11 / 25], [train loss 1.67410]\n",
            "[epoch 12], [iter 12 / 25], [train loss 1.69271]\n",
            "[epoch 12], [iter 13 / 25], [train loss 1.66767]\n",
            "[epoch 12], [iter 14 / 25], [train loss 1.64233]\n",
            "[epoch 12], [iter 15 / 25], [train loss 1.63888]\n",
            "[epoch 12], [iter 16 / 25], [train loss 1.61998]\n",
            "[epoch 12], [iter 17 / 25], [train loss 1.58322]\n",
            "[epoch 12], [iter 18 / 25], [train loss 1.60450]\n",
            "[epoch 12], [iter 19 / 25], [train loss 1.59104]\n",
            "[epoch 12], [iter 20 / 25], [train loss 1.59147]\n",
            "[epoch 12], [iter 21 / 25], [train loss 1.57071]\n",
            "[epoch 12], [iter 22 / 25], [train loss 1.56734]\n",
            "[epoch 12], [iter 23 / 25], [train loss 1.57110]\n",
            "[epoch 12], [iter 24 / 25], [train loss 1.59629]\n",
            "[epoch 12], [iter 25 / 25], [train loss 1.58440]\n",
            "Exiting...\n",
            "[epoch 13], [iter 1 / 25], [train loss 1.45320]\n",
            "[epoch 13], [iter 2 / 25], [train loss 1.55487]\n",
            "[epoch 13], [iter 3 / 25], [train loss 1.45173]\n",
            "[epoch 13], [iter 4 / 25], [train loss 1.46577]\n",
            "[epoch 13], [iter 5 / 25], [train loss 1.48770]\n",
            "[epoch 13], [iter 6 / 25], [train loss 1.43645]\n",
            "[epoch 13], [iter 7 / 25], [train loss 1.45460]\n",
            "[epoch 13], [iter 8 / 25], [train loss 1.39265]\n",
            "[epoch 13], [iter 9 / 25], [train loss 1.36798]\n",
            "[epoch 13], [iter 10 / 25], [train loss 1.39525]\n",
            "[epoch 13], [iter 11 / 25], [train loss 1.38407]\n",
            "[epoch 13], [iter 12 / 25], [train loss 1.35472]\n",
            "[epoch 13], [iter 13 / 25], [train loss 1.38021]\n",
            "[epoch 13], [iter 14 / 25], [train loss 1.43403]\n",
            "[epoch 13], [iter 15 / 25], [train loss 1.40904]\n",
            "[epoch 13], [iter 16 / 25], [train loss 1.42416]\n",
            "[epoch 13], [iter 17 / 25], [train loss 1.42897]\n",
            "[epoch 13], [iter 18 / 25], [train loss 1.43103]\n",
            "[epoch 13], [iter 19 / 25], [train loss 1.41894]\n",
            "[epoch 13], [iter 20 / 25], [train loss 1.37325]\n",
            "[epoch 13], [iter 21 / 25], [train loss 1.36058]\n",
            "[epoch 13], [iter 22 / 25], [train loss 1.35996]\n",
            "[epoch 13], [iter 23 / 25], [train loss 1.36899]\n",
            "[epoch 13], [iter 24 / 25], [train loss 1.37737]\n",
            "[epoch 13], [iter 25 / 25], [train loss 1.38326]\n",
            "Exiting...\n",
            "[epoch 14], [iter 1 / 25], [train loss 2.34714]\n",
            "[epoch 14], [iter 2 / 25], [train loss 1.59088]\n",
            "[epoch 14], [iter 3 / 25], [train loss 1.51611]\n",
            "[epoch 14], [iter 4 / 25], [train loss 1.56251]\n",
            "[epoch 14], [iter 5 / 25], [train loss 1.50704]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), os.path.join(ckpt_path, exp_name, 'model_' + str(epoch) + '.pth'))\n",
        "torch.save(optimizer.state_dict(), os.path.join(ckpt_path, exp_name, 'opt_' + str(epoch) + '.pth'))"
      ],
      "metadata": {
        "id": "rz3yF_V1djlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(valloader, model, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, HiddenClasses, {}, True, False)"
      ],
      "metadata": {
        "id": "7fabijUW2VAc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59a7402a-5546-4a69-f7f5-c65a5555c42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Batch 1/6\n",
            "    Test MiniBatch 1/53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Elapsed Time: 41.99\n",
            "    Test MiniBatch 2/53\n",
            "        Elapsed Time: 42.19\n",
            "    Test MiniBatch 3/53\n",
            "        Elapsed Time: 41.91\n",
            "    Test MiniBatch 4/53\n",
            "        Elapsed Time: 41.92\n",
            "    Test MiniBatch 5/53\n",
            "        Elapsed Time: 42.33\n",
            "    Test MiniBatch 6/53\n",
            "        Elapsed Time: 42.44\n",
            "    Test MiniBatch 7/53\n",
            "        Elapsed Time: 42.69\n",
            "    Test MiniBatch 8/53\n",
            "        Elapsed Time: 42.55\n",
            "    Test MiniBatch 9/53\n",
            "        Elapsed Time: 42.77\n",
            "    Test MiniBatch 10/53\n",
            "        Elapsed Time: 42.84\n",
            "    Test MiniBatch 11/53\n",
            "        Elapsed Time: 42.44\n",
            "    Test MiniBatch 12/53\n",
            "        Elapsed Time: 42.41\n",
            "    Test MiniBatch 13/53\n",
            "        Elapsed Time: 42.67\n",
            "    Test MiniBatch 14/53\n",
            "        Elapsed Time: 42.72\n",
            "    Test MiniBatch 15/53\n",
            "        Elapsed Time: 42.51\n",
            "    Test MiniBatch 16/53\n",
            "        Elapsed Time: 42.94\n",
            "    Test MiniBatch 17/53\n",
            "        Elapsed Time: 42.53\n",
            "    Test MiniBatch 18/53\n",
            "        Elapsed Time: 42.84\n",
            "    Test MiniBatch 19/53\n",
            "        Elapsed Time: 43.06\n",
            "    Test MiniBatch 20/53\n",
            "        Elapsed Time: 42.71\n",
            "    Test MiniBatch 21/53\n",
            "        Elapsed Time: 42.66\n",
            "    Test MiniBatch 22/53\n",
            "        Elapsed Time: 43.23\n",
            "    Test MiniBatch 23/53\n",
            "        Elapsed Time: 43.00\n",
            "    Test MiniBatch 24/53\n",
            "        Elapsed Time: 42.78\n",
            "    Test MiniBatch 25/53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-31-f529038322fe>\", line 1, in <module>\n",
            "    test(valloader, model, criterion, optimizer, epoch, num_known_classes, num_unknown_classes, HiddenClasses, {}, True, False)\n",
            "  File \"<ipython-input-12-498cb0f3cefe>\", line 81, in test\n",
            "    plt.figure(figsize=(16, 6))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\", line 546, in figure\n",
            "    **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\", line 3357, in new_figure_manager\n",
            "    fig = fig_cls(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\", line 353, in __init__\n",
            "    self.dpi_scale_trans = Affine2D().scale(dpi)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/matplotlib/transforms.py\", line 2002, in scale\n",
            "    self.invalidate()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/matplotlib/transforms.py\", line 134, in invalidate\n",
            "    return self._invalidate_internal(value, invalidating_node=self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/matplotlib/transforms.py\", line 136, in _invalidate_internal\n",
            "    def _invalidate_internal(self, value, invalidating_node):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1464, in getframeinfo\n",
            "    lines, lnum = findsource(frame)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
            "    lines = linecache.getlines(file, globals_dict)\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 47, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.7/tokenize.py\", line 449, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.7/tokenize.py\", line 418, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.7/tokenize.py\", line 376, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    }
  ]
}